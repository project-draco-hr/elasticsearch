{
  IndexService indexService=null;
  if (shardId != null) {
    indexService=indicesService.indexServiceSafe(shardId.getIndex());
  }
  Analyzer analyzer=null;
  boolean closeAnalyzer=false;
  String field=null;
  if (request.field() != null) {
    if (indexService == null) {
      throw new IllegalArgumentException("No index provided, and trying to analyzer based on a specific field which requires the index parameter");
    }
    FieldMapper fieldMapper=indexService.mapperService().smartNameFieldMapper(request.field());
    if (fieldMapper != null) {
      if (fieldMapper.isNumeric()) {
        throw new IllegalArgumentException("Can't process field [" + request.field() + "], Analysis requests are not supported on numeric fields");
      }
      analyzer=fieldMapper.fieldType().indexAnalyzer();
      field=fieldMapper.fieldType().names().indexName();
    }
  }
  if (field == null) {
    if (indexService != null) {
      field=indexService.queryParserService().defaultField();
    }
 else {
      field=AllFieldMapper.NAME;
    }
  }
  if (analyzer == null && request.analyzer() != null) {
    if (indexService == null) {
      analyzer=indicesAnalysisService.analyzer(request.analyzer());
    }
 else {
      analyzer=indexService.analysisService().analyzer(request.analyzer());
    }
    if (analyzer == null) {
      throw new IllegalArgumentException("failed to find analyzer [" + request.analyzer() + "]");
    }
  }
 else   if (request.tokenizer() != null) {
    TokenizerFactory tokenizerFactory;
    if (indexService == null) {
      TokenizerFactoryFactory tokenizerFactoryFactory=indicesAnalysisService.tokenizerFactoryFactory(request.tokenizer());
      if (tokenizerFactoryFactory == null) {
        throw new IllegalArgumentException("failed to find global tokenizer under [" + request.tokenizer() + "]");
      }
      tokenizerFactory=tokenizerFactoryFactory.create(request.tokenizer(),DEFAULT_SETTINGS);
    }
 else {
      tokenizerFactory=indexService.analysisService().tokenizer(request.tokenizer());
      if (tokenizerFactory == null) {
        throw new IllegalArgumentException("failed to find tokenizer under [" + request.tokenizer() + "]");
      }
    }
    TokenFilterFactory[] tokenFilterFactories=new TokenFilterFactory[0];
    if (request.tokenFilters() != null && request.tokenFilters().length > 0) {
      tokenFilterFactories=new TokenFilterFactory[request.tokenFilters().length];
      for (int i=0; i < request.tokenFilters().length; i++) {
        String tokenFilterName=request.tokenFilters()[i];
        if (indexService == null) {
          TokenFilterFactoryFactory tokenFilterFactoryFactory=indicesAnalysisService.tokenFilterFactoryFactory(tokenFilterName);
          if (tokenFilterFactoryFactory == null) {
            throw new IllegalArgumentException("failed to find global token filter under [" + tokenFilterName + "]");
          }
          tokenFilterFactories[i]=tokenFilterFactoryFactory.create(tokenFilterName,DEFAULT_SETTINGS);
        }
 else {
          tokenFilterFactories[i]=indexService.analysisService().tokenFilter(tokenFilterName);
          if (tokenFilterFactories[i] == null) {
            throw new IllegalArgumentException("failed to find token filter under [" + tokenFilterName + "]");
          }
        }
        if (tokenFilterFactories[i] == null) {
          throw new IllegalArgumentException("failed to find token filter under [" + tokenFilterName + "]");
        }
      }
    }
    CharFilterFactory[] charFilterFactories=new CharFilterFactory[0];
    if (request.charFilters() != null && request.charFilters().length > 0) {
      charFilterFactories=new CharFilterFactory[request.charFilters().length];
      for (int i=0; i < request.charFilters().length; i++) {
        String charFilterName=request.charFilters()[i];
        if (indexService == null) {
          CharFilterFactoryFactory charFilterFactoryFactory=indicesAnalysisService.charFilterFactoryFactory(charFilterName);
          if (charFilterFactoryFactory == null) {
            throw new IllegalArgumentException("failed to find global char filter under [" + charFilterName + "]");
          }
          charFilterFactories[i]=charFilterFactoryFactory.create(charFilterName,DEFAULT_SETTINGS);
        }
 else {
          charFilterFactories[i]=indexService.analysisService().charFilter(charFilterName);
          if (charFilterFactories[i] == null) {
            throw new IllegalArgumentException("failed to find token char under [" + charFilterName + "]");
          }
        }
        if (charFilterFactories[i] == null) {
          throw new IllegalArgumentException("failed to find token char under [" + charFilterName + "]");
        }
      }
    }
    analyzer=new CustomAnalyzer(tokenizerFactory,charFilterFactories,tokenFilterFactories);
    closeAnalyzer=true;
  }
 else   if (analyzer == null) {
    if (indexService == null) {
      analyzer=indicesAnalysisService.analyzer("standard");
    }
 else {
      analyzer=indexService.analysisService().defaultIndexAnalyzer();
    }
  }
  if (analyzer == null) {
    throw new IllegalArgumentException("failed to find analyzer");
  }
  List<AnalyzeResponse.AnalyzeToken> tokens=Lists.newArrayList();
  TokenStream stream=null;
  int lastPosition=-1;
  int lastOffset=0;
  for (  String text : request.text()) {
    try {
      stream=analyzer.tokenStream(field,text);
      stream.reset();
      CharTermAttribute term=stream.addAttribute(CharTermAttribute.class);
      PositionIncrementAttribute posIncr=stream.addAttribute(PositionIncrementAttribute.class);
      OffsetAttribute offset=stream.addAttribute(OffsetAttribute.class);
      TypeAttribute type=stream.addAttribute(TypeAttribute.class);
      while (stream.incrementToken()) {
        int increment=posIncr.getPositionIncrement();
        if (increment > 0) {
          lastPosition=lastPosition + increment;
        }
        tokens.add(new AnalyzeResponse.AnalyzeToken(term.toString(),lastPosition,lastOffset + offset.startOffset(),lastOffset + offset.endOffset(),type.type()));
      }
      stream.end();
      lastOffset+=offset.endOffset();
      lastPosition+=posIncr.getPositionIncrement();
      lastPosition+=analyzer.getPositionIncrementGap(field);
      lastOffset+=analyzer.getOffsetGap(field);
    }
 catch (    IOException e) {
      throw new ElasticsearchException("failed to analyze",e);
    }
 finally {
      IOUtils.closeWhileHandlingException(stream);
    }
  }
  if (closeAnalyzer) {
    analyzer.close();
  }
  return new AnalyzeResponse(tokens);
}
