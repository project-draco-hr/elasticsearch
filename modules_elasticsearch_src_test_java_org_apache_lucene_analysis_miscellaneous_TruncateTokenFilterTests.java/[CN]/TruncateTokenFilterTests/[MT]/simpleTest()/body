{
  Analyzer analyzer=new ReusableAnalyzerBase(){
    @Override protected TokenStreamComponents createComponents(    String fieldName,    Reader reader){
      Tokenizer t=new WhitespaceTokenizer(Lucene.VERSION,reader);
      return new TokenStreamComponents(t,new TruncateTokenFilter(t,3));
    }
  }
;
  TokenStream test=analyzer.reusableTokenStream("test",new StringReader("a bb ccc dddd eeeee"));
  CharTermAttribute termAttribute=test.addAttribute(CharTermAttribute.class);
  assertThat(test.incrementToken(),equalTo(true));
  assertThat(termAttribute.toString(),equalTo("a"));
  assertThat(test.incrementToken(),equalTo(true));
  assertThat(termAttribute.toString(),equalTo("bb"));
  assertThat(test.incrementToken(),equalTo(true));
  assertThat(termAttribute.toString(),equalTo("ccc"));
  assertThat(test.incrementToken(),equalTo(true));
  assertThat(termAttribute.toString(),equalTo("ddd"));
  assertThat(test.incrementToken(),equalTo(true));
  assertThat(termAttribute.toString(),equalTo("eee"));
  assertThat(test.incrementToken(),equalTo(false));
}
