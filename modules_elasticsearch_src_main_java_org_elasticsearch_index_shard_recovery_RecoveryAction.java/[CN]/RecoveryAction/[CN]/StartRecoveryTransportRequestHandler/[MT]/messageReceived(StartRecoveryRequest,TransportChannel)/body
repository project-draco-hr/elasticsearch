{
  if (!recoveryThrottler.tryRecovery(shardId,"peer recovery source")) {
    RecoveryStatus retry=new RecoveryStatus();
    retry.retry=true;
    channel.sendResponse(retry);
    return;
  }
  try {
    logger.trace("starting recovery to {}, mark_as_relocated {}",startRecoveryRequest.node,startRecoveryRequest.markAsRelocated);
    final DiscoveryNode node=startRecoveryRequest.node;
    cleanOpenIndex();
    final RecoveryStatus recoveryStatus=new RecoveryStatus();
    indexShard.recover(new Engine.RecoveryHandler(){
      @Override public void phase1(      final SnapshotIndexCommit snapshot) throws ElasticSearchException {
        long totalSize=0;
        long existingTotalSize=0;
        try {
          StopWatch stopWatch=new StopWatch().start();
          for (          String name : snapshot.getFiles()) {
            StoreFileMetaData md=store.metaDataWithMd5(name);
            boolean useExisting=false;
            if (startRecoveryRequest.existingFiles.containsKey(name)) {
              if (md.md5().equals(startRecoveryRequest.existingFiles.get(name).md5())) {
                recoveryStatus.phase1ExistingFileNames.add(name);
                recoveryStatus.phase1ExistingFileSizes.add(md.sizeInBytes());
                existingTotalSize+=md.sizeInBytes();
                useExisting=true;
                if (logger.isTraceEnabled()) {
                  logger.trace("not recovering [{}], exists in local store and has md5 [{}]",name,md.md5());
                }
              }
            }
            if (!useExisting) {
              recoveryStatus.phase1FileNames.add(name);
              recoveryStatus.phase1FileSizes.add(md.sizeInBytes());
              totalSize+=md.sizeInBytes();
            }
          }
          recoveryStatus.phase1TotalSize=totalSize;
          recoveryStatus.phase1ExistingTotalSize=existingTotalSize;
          final AtomicLong throttlingWaitTime=new AtomicLong();
          logger.trace("recovery [phase1] to {}: recovering_files [{}] with total_size [{}], reusing_files [{}] with total_size [{}]",node,recoveryStatus.phase1FileNames.size(),new ByteSizeValue(totalSize),recoveryStatus.phase1ExistingFileNames.size(),new ByteSizeValue(existingTotalSize));
          final CountDownLatch latch=new CountDownLatch(recoveryStatus.phase1FileNames.size());
          final AtomicReference<Exception> lastException=new AtomicReference<Exception>();
          for (          final String name : recoveryStatus.phase1FileNames) {
            sendFileChunksRecoveryFutures.add(threadPool.submit(new Runnable(){
              @Override public void run(){
                IndexInput indexInput=null;
                try {
                  long throttlingStartTime=System.currentTimeMillis();
                  while (!recoveryThrottler.tryStream(shardId,name)) {
                    Thread.sleep(recoveryThrottler.throttleInterval().millis());
                  }
                  throttlingWaitTime.addAndGet(System.currentTimeMillis() - throttlingStartTime);
                  final int BUFFER_SIZE=(int)fileChunkSize.bytes();
                  byte[] buf=new byte[BUFFER_SIZE];
                  indexInput=snapshot.getDirectory().openInput(name);
                  long len=indexInput.length();
                  long readCount=0;
                  while (readCount < len) {
                    int toRead=readCount + BUFFER_SIZE > len ? (int)(len - readCount) : BUFFER_SIZE;
                    long position=indexInput.getFilePointer();
                    indexInput.readBytes(buf,0,toRead,false);
                    transportService.submitRequest(node,fileChunkTransportAction,new FileChunk(name,position,len,buf,toRead),VoidTransportResponseHandler.INSTANCE).txGet(120,SECONDS);
                    readCount+=toRead;
                  }
                  indexInput.close();
                }
 catch (                Exception e) {
                  lastException.set(e);
                }
 finally {
                  recoveryThrottler.streamDone(shardId,name);
                  if (indexInput != null) {
                    try {
                      indexInput.close();
                    }
 catch (                    IOException e) {
                    }
                  }
                  latch.countDown();
                }
              }
            }
));
          }
          latch.await();
          if (lastException.get() != null) {
            throw lastException.get();
          }
          CleanFilesRequest cleanFilesRequest=new CleanFilesRequest();
          cleanFilesRequest.snapshotFiles.addAll(Arrays.asList(snapshot.getFiles()));
          transportService.submitRequest(node,cleanFilesTransportAction,cleanFilesRequest,VoidTransportResponseHandler.INSTANCE).txGet();
          stopWatch.stop();
          logger.trace("recovery [phase1] to {}: took [{}], throttling_wait [{}]",node,stopWatch.totalTime(),timeValueMillis(throttlingWaitTime.get()));
          recoveryStatus.phase1Time=stopWatch.totalTime().millis();
        }
 catch (        ElasticSearchInterruptedException e) {
          throw new IgnoreRecoveryException("Interrupted while recovering files");
        }
catch (        Throwable e) {
          throw new RecoverFilesRecoveryException(shardId,recoveryStatus.phase1FileNames.size(),new ByteSizeValue(totalSize),e);
        }
 finally {
          sendFileChunksRecoveryFutures.clear();
        }
      }
      @Override public void phase2(      Translog.Snapshot snapshot) throws ElasticSearchException {
        sendSnapshotRecoveryThread=Thread.currentThread();
        try {
          if (closed) {
            throw new IndexShardClosedException(shardId);
          }
          logger.trace("recovery [phase2] to {}: sending [{}] transaction log operations",node,snapshot.size());
          StopWatch stopWatch=new StopWatch().start();
          transportService.submitRequest(node,prepareForTranslogOperationsTransportAction,VoidStreamable.INSTANCE,VoidTransportResponseHandler.INSTANCE).txGet();
          sendSnapshot(snapshot);
          stopWatch.stop();
          logger.trace("recovery [phase2] to {}: took [{}]",node,stopWatch.totalTime());
          recoveryStatus.phase2Time=stopWatch.totalTime().millis();
          recoveryStatus.phase2Operations=snapshot.size();
        }
 catch (        ElasticSearchInterruptedException e) {
          throw new IgnoreRecoveryException("Interrupted in phase 2 files");
        }
 finally {
          sendSnapshotRecoveryThread=null;
        }
      }
      @Override public void phase3(      Translog.Snapshot snapshot) throws ElasticSearchException {
        sendSnapshotRecoveryThread=Thread.currentThread();
        try {
          if (closed) {
            throw new IndexShardClosedException(shardId);
          }
          logger.trace("recovery [phase3] to {}: sending [{}] transaction log operations",node,snapshot.size());
          StopWatch stopWatch=new StopWatch().start();
          sendSnapshot(snapshot);
          transportService.submitRequest(node,finalizeRecoveryTransportAction,VoidStreamable.INSTANCE,VoidTransportResponseHandler.INSTANCE).txGet();
          if (startRecoveryRequest.markAsRelocated) {
            try {
              indexShard.relocated();
            }
 catch (            IllegalIndexShardStateException e) {
            }
          }
          stopWatch.stop();
          logger.trace("recovery [phase3] to {}: took [{}]",node,stopWatch.totalTime());
          recoveryStatus.phase3Time=stopWatch.totalTime().millis();
          recoveryStatus.phase3Operations=snapshot.size();
        }
 catch (        ElasticSearchInterruptedException e) {
          throw new IgnoreRecoveryException("Interrupted in phase 2 files");
        }
 finally {
          sendSnapshotRecoveryThread=null;
        }
      }
      private void sendSnapshot(      Translog.Snapshot snapshot) throws ElasticSearchException {
        TranslogOperationsRequest request=new TranslogOperationsRequest();
        for (        Translog.Operation operation : snapshot) {
          request.operations.add(operation);
        }
        transportService.submitRequest(node,translogOperationsTransportAction,request,VoidTransportResponseHandler.INSTANCE).txGet();
      }
    }
);
    channel.sendResponse(recoveryStatus);
  }
  finally {
    recoveryThrottler.recoveryDone(shardId,"peer recovery source");
  }
}
