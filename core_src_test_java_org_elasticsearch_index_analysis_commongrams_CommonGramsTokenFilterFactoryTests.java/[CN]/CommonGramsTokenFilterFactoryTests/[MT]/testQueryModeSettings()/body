{
{
    Settings settings=Settings.builder().put("index.analysis.filter.common_grams_1.type","common_grams").put("index.analysis.filter.common_grams_1.query_mode",true).putArray("index.analysis.filter.common_grams_1.common_words","the","Or","Not","a","is","an","they","are").put("index.analysis.filter.common_grams_1.ignore_case",true).put(Environment.PATH_HOME_SETTING.getKey(),createTempDir().toString()).build();
    ESTestCase.TestAnalysis analysis=AnalysisTestsHelper.createTestAnalysisFromSettings(settings);
    TokenFilterFactory tokenFilter=analysis.tokenFilter.get("common_grams_1");
    String source="the quick brown is a fox or noT";
    String[] expected=new String[]{"the_quick","quick","brown_is","is_a","a_fox","fox_or","or_noT"};
    Tokenizer tokenizer=new WhitespaceTokenizer();
    tokenizer.setReader(new StringReader(source));
    assertTokenStreamContents(tokenFilter.create(tokenizer),expected);
  }
{
    Settings settings=Settings.builder().put("index.analysis.filter.common_grams_2.type","common_grams").put("index.analysis.filter.common_grams_2.query_mode",true).putArray("index.analysis.filter.common_grams_2.common_words","the","Or","noT","a","is","an","they","are").put("index.analysis.filter.common_grams_2.ignore_case",false).put(Environment.PATH_HOME_SETTING.getKey(),createTempDir().toString()).build();
    ESTestCase.TestAnalysis analysis=AnalysisTestsHelper.createTestAnalysisFromSettings(settings);
    TokenFilterFactory tokenFilter=analysis.tokenFilter.get("common_grams_2");
    String source="the quick brown is a fox or why noT";
    String[] expected=new String[]{"the_quick","quick","brown_is","is_a","a_fox","fox","or","why_noT"};
    Tokenizer tokenizer=new WhitespaceTokenizer();
    tokenizer.setReader(new StringReader(source));
    assertTokenStreamContents(tokenFilter.create(tokenizer),expected);
  }
{
    Settings settings=Settings.builder().put("index.analysis.filter.common_grams_3.type","common_grams").put("index.analysis.filter.common_grams_3.query_mode",true).putArray("index.analysis.filter.common_grams_3.common_words","the","Or","noT","a","is","an","they","are").put(Environment.PATH_HOME_SETTING.getKey(),createTempDir().toString()).build();
    ESTestCase.TestAnalysis analysis=AnalysisTestsHelper.createTestAnalysisFromSettings(settings);
    TokenFilterFactory tokenFilter=analysis.tokenFilter.get("common_grams_3");
    String source="the quick brown is a fox or why noT";
    String[] expected=new String[]{"the_quick","quick","brown_is","is_a","a_fox","fox","or","why_noT"};
    Tokenizer tokenizer=new WhitespaceTokenizer();
    tokenizer.setReader(new StringReader(source));
    assertTokenStreamContents(tokenFilter.create(tokenizer),expected);
  }
{
    Settings settings=Settings.builder().put("index.analysis.filter.common_grams_4.type","common_grams").put("index.analysis.filter.common_grams_4.query_mode",true).putArray("index.analysis.filter.common_grams_4.common_words","the","or","not","a","is","an","they","are").put(Environment.PATH_HOME_SETTING.getKey(),createTempDir().toString()).build();
    ESTestCase.TestAnalysis analysis=AnalysisTestsHelper.createTestAnalysisFromSettings(settings);
    TokenFilterFactory tokenFilter=analysis.tokenFilter.get("common_grams_4");
    String source="the quick brown is a fox Or noT";
    String[] expected=new String[]{"the_quick","quick","brown_is","is_a","a_fox","fox","Or","noT"};
    Tokenizer tokenizer=new WhitespaceTokenizer();
    tokenizer.setReader(new StringReader(source));
    assertTokenStreamContents(tokenFilter.create(tokenizer),expected);
  }
}
