{
  List<InternalAggregation> aggregations=reduceContext.aggregations();
  if (aggregations.size() == 1) {
    InternalTerms terms=(InternalTerms)aggregations.get(0);
    terms.trimExcessEntries(reduceContext.cacheRecycler());
    return terms;
  }
  InternalTerms reduced=null;
  Map<Text,List<InternalTerms.Bucket>> buckets=null;
  for (  InternalAggregation aggregation : aggregations) {
    InternalTerms terms=(InternalTerms)aggregation;
    if (terms instanceof UnmappedTerms) {
      continue;
    }
    if (reduced == null) {
      reduced=terms;
    }
    if (buckets == null) {
      buckets=new HashMap<Text,List<Bucket>>(terms.buckets.size());
    }
    for (    Bucket bucket : terms.buckets) {
      List<Bucket> existingBuckets=buckets.get(bucket.getKey());
      if (existingBuckets == null) {
        existingBuckets=new ArrayList<Bucket>(aggregations.size());
        buckets.put(bucket.getKey(),existingBuckets);
      }
      existingBuckets.add(bucket);
    }
  }
  if (reduced == null) {
    return (UnmappedTerms)aggregations.get(0);
  }
  final int size=Math.min(requiredSize,buckets.size());
  BucketPriorityQueue ordered=new BucketPriorityQueue(size,order.comparator(null));
  for (  Map.Entry<Text,List<Bucket>> entry : buckets.entrySet()) {
    List<Bucket> sameTermBuckets=entry.getValue();
    final Bucket b=sameTermBuckets.get(0).reduce(sameTermBuckets,reduceContext.cacheRecycler());
    if (b.docCount >= minDocCount) {
      ordered.insertWithOverflow(b);
    }
  }
  Bucket[] list=new Bucket[ordered.size()];
  for (int i=ordered.size() - 1; i >= 0; i--) {
    list[i]=(Bucket)ordered.pop();
  }
  reduced.buckets=Arrays.asList(list);
  return reduced;
}
