{
  Settings settings=settingsBuilder().put("index.refresh_interval","-1").put("node.local",true).put(SETTING_NUMBER_OF_SHARDS,1).put(SETTING_NUMBER_OF_REPLICAS,0).build();
  String clusterName=TimeDataHistogramAggregationBenchmark.class.getSimpleName();
  Node[] nodes=new Node[1];
  for (int i=0; i < nodes.length; i++) {
    nodes[i]=nodeBuilder().clusterName(clusterName).settings(settingsBuilder().put(settings).put("name","node" + i)).node();
  }
  client=nodes[0].client();
  Thread.sleep(10000);
  try {
    client.admin().indices().create(createIndexRequest("test")).actionGet();
    StopWatch stopWatch=new StopWatch().start();
    System.out.println("--> Indexing [" + COUNT + "] ...");
    long ITERS=COUNT / BATCH;
    long i=1;
    int counter=0;
    long[] currentTimeInMillis1=new long[]{System.currentTimeMillis()};
    long[] currentTimeInMillis2=new long[]{System.currentTimeMillis()};
    long startTimeInMillis=currentTimeInMillis1[0];
    long averageMillisChange=TIME_PERIOD / COUNT * 2;
    long backwardSkew=Math.max(1,(long)(averageMillisChange * 0.1));
    long bigOutOfOrder=1;
    for (; i <= ITERS; i++) {
      BulkRequestBuilder request=client.prepareBulk();
      for (int j=0; j < BATCH; j++) {
        counter++;
        XContentBuilder builder=jsonBuilder().startObject();
        builder.field("id",Integer.toString(counter));
        long diff=ThreadLocalRandom.current().nextLong(2 * averageMillisChange + 2 * backwardSkew) - backwardSkew;
        long[] currentTime=counter % 2 == 0 ? currentTimeInMillis1 : currentTimeInMillis2;
        currentTime[0]+=diff;
        if (ThreadLocalRandom.current().nextLong(100) <= bigOutOfOrder) {
          builder.field("l_value",currentTime[0] - 60000);
        }
 else {
          builder.field("l_value",currentTime[0]);
        }
        builder.endObject();
        request.add(Requests.indexRequest("test").type("type1").id(Integer.toString(counter)).source(builder));
      }
      BulkResponse response=request.execute().actionGet();
      if (response.hasFailures()) {
        System.err.println("--> failures...");
      }
      if (((i * BATCH) % 10000) == 0) {
        System.out.println("--> Indexed " + (i * BATCH) + " took "+ stopWatch.stop().lastTaskTime());
        stopWatch.start();
      }
    }
    System.out.println("--> Indexing took " + stopWatch.totalTime() + ", TPS "+ (((double)(COUNT)) / stopWatch.totalTime().secondsFrac()));
    System.out.println("Time range 1: " + (currentTimeInMillis1[0] - startTimeInMillis) / 1000.0 / 3600 + " hours");
    System.out.println("Time range 2: " + (currentTimeInMillis2[0] - startTimeInMillis) / 1000.0 / 3600 + " hours");
    System.out.println("--> optimizing index");
    client.admin().indices().prepareOptimize().setMaxNumSegments(1).get();
  }
 catch (  IndexAlreadyExistsException e) {
    System.out.println("--> Index already exists, ignoring indexing phase, waiting for green");
    ClusterHealthResponse clusterHealthResponse=client.admin().cluster().prepareHealth().setWaitForGreenStatus().setTimeout("10m").execute().actionGet();
    if (clusterHealthResponse.isTimedOut()) {
      System.err.println("--> Timed out waiting for cluster health");
    }
  }
  client.admin().indices().prepareRefresh().execute().actionGet();
  COUNT=client.prepareCount().setQuery(matchAllQuery()).execute().actionGet().getCount();
  System.out.println("--> Number of docs in index: " + COUNT);
  setMapping(ACCEPTABLE_OVERHEAD_RATIO,MEMORY_FORMAT.equals(IndexFieldData.CommonSettings.MemoryStorageFormat.PACKED) ? IndexFieldData.CommonSettings.MemoryStorageFormat.PAGED : IndexFieldData.CommonSettings.MemoryStorageFormat.PACKED);
  warmUp("hist_l","l_value",MATCH_PERCENTAGE);
  setMapping(ACCEPTABLE_OVERHEAD_RATIO,MEMORY_FORMAT);
  warmUp("hist_l","l_value",MATCH_PERCENTAGE);
  List<StatsResult> stats=Lists.newArrayList();
  stats.add(measureAgg("hist_l","l_value",MATCH_PERCENTAGE));
  NodesStatsResponse nodeStats=client.admin().cluster().prepareNodesStats(nodes[0].settings().get("name")).clear().setIndices(new CommonStatsFlags(CommonStatsFlags.Flag.FieldData)).get();
  System.out.println("------------------ SUMMARY -------------------------------");
  System.out.println("docs: " + COUNT);
  System.out.println("match percentage: " + MATCH_PERCENTAGE);
  System.out.println("memory format hint: " + MEMORY_FORMAT);
  System.out.println("acceptable_overhead_ratio: " + ACCEPTABLE_OVERHEAD_RATIO);
  System.out.println("field data: " + nodeStats.getNodes()[0].getIndices().getFieldData().getMemorySize());
  System.out.format(Locale.ROOT,"%25s%10s%10s\n","name","took","millis");
  for (  StatsResult stat : stats) {
    System.out.format(Locale.ROOT,"%25s%10s%10d\n",stat.name,TimeValue.timeValueMillis(stat.took),(stat.took / QUERY_COUNT));
  }
  System.out.println("------------------ SUMMARY -------------------------------");
  for (  Node node : nodes) {
    node.close();
  }
}
