{
  MapBinder<String,TokenFilterFactoryFactory> tokenFilterBinder=MapBinder.newMapBinder(binder(),String.class,TokenFilterFactoryFactory.class);
  Map<String,Settings> tokenFiltersSettings=settings.getGroups("index.analysis.filter");
  for (  Map.Entry<String,Settings> entry : tokenFiltersSettings.entrySet()) {
    String tokenFilterName=entry.getKey();
    Settings tokenFilterSettings=entry.getValue();
    Class<? extends TokenFilterFactory> type=tokenFilterSettings.getAsClass("type",null,"org.elasticsearch.index.analysis.","TokenFilterFactory");
    if (type == null) {
      throw new IllegalArgumentException("Token Filter [" + tokenFilterName + "] must have a type associated with it");
    }
    tokenFilterBinder.addBinding(tokenFilterName).toProvider(FactoryProvider.newFactory(TokenFilterFactoryFactory.class,type)).in(Scopes.SINGLETON);
  }
  AnalysisBinderProcessor.TokenFiltersBindings tokenFiltersBindings=new AnalysisBinderProcessor.TokenFiltersBindings(tokenFilterBinder,tokenFiltersSettings);
  for (  AnalysisBinderProcessor processor : processors) {
    processor.processTokenFilters(tokenFiltersBindings);
  }
  MapBinder<String,TokenizerFactoryFactory> tokenizerBinder=MapBinder.newMapBinder(binder(),String.class,TokenizerFactoryFactory.class);
  Map<String,Settings> tokenizersSettings=settings.getGroups("index.analysis.tokenizer");
  for (  Map.Entry<String,Settings> entry : tokenizersSettings.entrySet()) {
    String tokenizerName=entry.getKey();
    Settings tokenizerSettings=entry.getValue();
    Class<? extends TokenizerFactory> type=tokenizerSettings.getAsClass("type",null,"org.elasticsearch.index.analysis.","TokenizerFactory");
    if (type == null) {
      throw new IllegalArgumentException("Tokenizer [" + tokenizerName + "] must have a type associated with it");
    }
    tokenizerBinder.addBinding(tokenizerName).toProvider(FactoryProvider.newFactory(TokenizerFactoryFactory.class,type)).in(Scopes.SINGLETON);
  }
  AnalysisBinderProcessor.TokenizersBindings tokenizersBindings=new AnalysisBinderProcessor.TokenizersBindings(tokenizerBinder,tokenizersSettings);
  for (  AnalysisBinderProcessor processor : processors) {
    processor.processTokenizers(tokenizersBindings);
  }
  MapBinder<String,AnalyzerProviderFactory> analyzerBinder=MapBinder.newMapBinder(binder(),String.class,AnalyzerProviderFactory.class);
  Map<String,Settings> analyzersSettings=settings.getGroups("index.analysis.analyzer");
  for (  Map.Entry<String,Settings> entry : analyzersSettings.entrySet()) {
    String analyzerName=entry.getKey();
    Settings analyzerSettings=entry.getValue();
    Class<? extends AnalyzerProvider> type=analyzerSettings.getAsClass("type",null,"org.elasticsearch.index.analysis.","AnalyzerProvider");
    if (type == null) {
      String tokenizerName=analyzerSettings.get("tokenizer");
      if (tokenizerName != null) {
        type=CustomAnalyzerProvider.class;
      }
 else {
        throw new IllegalArgumentException("Analyzer [" + analyzerName + "] must have a type associated with it or a tokenizer");
      }
    }
    analyzerBinder.addBinding(analyzerName).toProvider(FactoryProvider.newFactory(AnalyzerProviderFactory.class,type)).in(Scopes.SINGLETON);
  }
  AnalysisBinderProcessor.AnalyzersBindings analyzersBindings=new AnalysisBinderProcessor.AnalyzersBindings(analyzerBinder,analyzersSettings,indicesAnalysisService);
  for (  AnalysisBinderProcessor processor : processors) {
    processor.processAnalyzers(analyzersBindings);
  }
  bind(AnalysisService.class).in(Scopes.SINGLETON);
}
