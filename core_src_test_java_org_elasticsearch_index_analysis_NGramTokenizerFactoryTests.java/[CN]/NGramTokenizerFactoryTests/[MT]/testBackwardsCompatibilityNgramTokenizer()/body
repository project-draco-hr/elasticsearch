{
  int iters=scaledRandomIntBetween(20,100);
  for (int i=0; i < iters; i++) {
    final Index index=new Index("test");
    final String name="ngr";
    Version v=randomVersion(random());
    if (v.onOrAfter(Version.V_0_90_2)) {
      Builder builder=newAnalysisSettingsBuilder().put("min_gram",2).put("max_gram",3).put("token_chars","letter,digit");
      boolean compatVersion=false;
      if ((compatVersion=random().nextBoolean())) {
        builder.put("version","4." + random().nextInt(3));
      }
      Settings settings=builder.build();
      Settings indexSettings=newAnalysisSettingsBuilder().put(IndexMetaData.SETTING_VERSION_CREATED,v.id).build();
      Tokenizer nGramTokenizer=new NGramTokenizerFactory(IndexSettingsModule.newIndexSettings(index,indexSettings,Collections.EMPTY_LIST),name,settings).create();
      nGramTokenizer.setReader(new StringReader("foo bar"));
      if (compatVersion) {
        assertThat(nGramTokenizer,instanceOf(Lucene43NGramTokenizer.class));
      }
 else {
        assertThat(nGramTokenizer,instanceOf(NGramTokenizer.class));
      }
    }
 else {
      Settings settings=newAnalysisSettingsBuilder().put("min_gram",2).put("max_gram",3).build();
      Settings indexSettings=newAnalysisSettingsBuilder().put(IndexMetaData.SETTING_VERSION_CREATED,v.id).build();
      Tokenizer nGramTokenizer=new NGramTokenizerFactory(IndexSettingsModule.newIndexSettings(index,indexSettings,Collections.EMPTY_LIST),name,settings).create();
      nGramTokenizer.setReader(new StringReader("foo bar"));
      assertThat(nGramTokenizer,instanceOf(Lucene43NGramTokenizer.class));
    }
  }
}
