{
  final Index index=new Index("test");
  final String name="ngr";
  final Settings indexSettings=newAnalysisSettingsBuilder().build();
  Settings settings=newAnalysisSettingsBuilder().put("min_gram",2).put("max_gram",3).put("token_chars","letter,digit").build();
  Tokenizer tokenizer=new NGramTokenizerFactory(new IndexSettings(index,indexSettings,Collections.EMPTY_LIST),name,settings).create();
  tokenizer.setReader(new StringReader("??bc d??f g\uD801\uDC00f "));
  assertTokenStreamContents(tokenizer,new String[]{"??b","??bc","bc","d??","d??f","??f","g\uD801\uDC00","g\uD801\uDC00f","\uD801\uDC00f"});
  settings=newAnalysisSettingsBuilder().put("min_gram",2).put("max_gram",3).put("token_chars","letter,digit,punctuation,whitespace,symbol").build();
  tokenizer=new NGramTokenizerFactory(new IndexSettings(index,indexSettings,Collections.EMPTY_LIST),name,settings).create();
  tokenizer.setReader(new StringReader(" a!$ 9"));
  assertTokenStreamContents(tokenizer,new String[]{" a"," a!","a!","a!$","!$","!$ ","$ ","$ 9"," 9"});
}
