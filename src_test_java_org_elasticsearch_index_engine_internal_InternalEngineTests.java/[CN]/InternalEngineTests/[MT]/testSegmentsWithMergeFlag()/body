{
  final Store store=createStore();
  ConcurrentMergeSchedulerProvider mergeSchedulerProvider=new ConcurrentMergeSchedulerProvider(shardId,EMPTY_SETTINGS,threadPool,new IndexSettingsService(shardId.index(),EMPTY_SETTINGS));
  final AtomicReference<CountDownLatch> waitTillMerge=new AtomicReference<>();
  final AtomicReference<CountDownLatch> waitForMerge=new AtomicReference<>();
  mergeSchedulerProvider.addListener(new MergeSchedulerProvider.Listener(){
    @Override public void beforeMerge(    OnGoingMerge merge){
      try {
        if (waitTillMerge.get() != null) {
          waitTillMerge.get().countDown();
        }
        if (waitForMerge.get() != null) {
          waitForMerge.get().await();
        }
      }
 catch (      InterruptedException e) {
        throw ExceptionsHelper.convertToRuntime(e);
      }
    }
    @Override public void afterMerge(    OnGoingMerge merge){
    }
  }
);
  final Engine engine=createEngine(engineSettingsService,store,createTranslog(),mergeSchedulerProvider);
  engine.start();
  ParsedDocument doc=testParsedDocument("1","1","test",null,-1,-1,testDocument(),Lucene.STANDARD_ANALYZER,B_1,false);
  Engine.Index index=new Engine.Index(null,newUid("1"),doc);
  engine.index(index);
  engine.flush(Engine.FlushType.COMMIT_TRANSLOG,false,false);
  assertThat(engine.segments().size(),equalTo(1));
  index=new Engine.Index(null,newUid("2"),doc);
  engine.index(index);
  engine.flush(Engine.FlushType.COMMIT_TRANSLOG,false,false);
  assertThat(engine.segments().size(),equalTo(2));
  for (  Segment segment : engine.segments()) {
    assertThat(segment.getMergeId(),nullValue());
  }
  index=new Engine.Index(null,newUid("3"),doc);
  engine.index(index);
  engine.flush(Engine.FlushType.COMMIT_TRANSLOG,false,false);
  assertThat(engine.segments().size(),equalTo(3));
  for (  Segment segment : engine.segments()) {
    assertThat(segment.getMergeId(),nullValue());
  }
  waitTillMerge.set(new CountDownLatch(1));
  waitForMerge.set(new CountDownLatch(1));
  engine.forceMerge(false,false);
  waitTillMerge.get().await();
  for (  Segment segment : engine.segments()) {
    assertThat(segment.getMergeId(),notNullValue());
  }
  waitForMerge.get().countDown();
  index=new Engine.Index(null,newUid("4"),doc);
  engine.index(index);
  engine.flush(Engine.FlushType.COMMIT_TRANSLOG,false,false);
  final long gen1=store.readLastCommittedSegmentsInfo().getGeneration();
  engine.forceMerge(true,true);
  for (  Segment segment : engine.segments()) {
    assertThat(segment.getMergeId(),nullValue());
  }
  assertTrue(store.readLastCommittedSegmentsInfo().getGeneration() > gen1);
  final boolean flush=randomBoolean();
  final long gen2=store.readLastCommittedSegmentsInfo().getGeneration();
  engine.forceMerge(flush,false);
  waitTillMerge.get().await();
  for (  Segment segment : engine.segments()) {
    assertThat(segment.getMergeId(),nullValue());
  }
  waitForMerge.get().countDown();
  if (flush) {
    awaitBusy(new Predicate<Object>(){
      @Override public boolean apply(      Object o){
        try {
          return store.readLastCommittedSegmentsInfo().getLastGeneration() == gen2;
        }
 catch (        IOException e) {
          throw ExceptionsHelper.convertToRuntime(e);
        }
      }
    }
);
  }
  engine.close();
  store.close();
}
