{
  reset();
  return new TermsEnum(){
    int currentTerm=0;
    int freq=0;
    int docFreq=-1;
    long totalTermFrequency=-1;
    int[] positions=new int[1];
    int[] startOffsets=new int[1];
    int[] endOffsets=new int[1];
    BytesRefBuilder[] payloads=new BytesRefBuilder[1];
    final BytesRefBuilder spare=new BytesRefBuilder();
    BoostAttribute boostAtt=this.attributes().addAttribute(BoostAttribute.class);
    @Override public BytesRef next() throws IOException {
      if (currentTerm++ < numTerms) {
        int termVectorSize=perFieldTermVectorInput.readVInt();
        spare.grow(termVectorSize);
        perFieldTermVectorInput.readBytes(spare.bytes(),0,termVectorSize);
        spare.setLength(termVectorSize);
        if (hasTermStatistic) {
          docFreq=readPotentiallyNegativeVInt(perFieldTermVectorInput);
          totalTermFrequency=readPotentiallyNegativeVLong(perFieldTermVectorInput);
        }
        freq=readPotentiallyNegativeVInt(perFieldTermVectorInput);
        growBuffers();
        writeInfos(perFieldTermVectorInput);
        if (hasScores) {
          boostAtt.setBoost(perFieldTermVectorInput.readFloat());
        }
        return spare.get();
      }
 else {
        return null;
      }
    }
    private void writeInfos(    final StreamInput input) throws IOException {
      for (int i=0; i < freq; i++) {
        if (hasPositions) {
          positions[i]=input.readVInt();
        }
        if (hasOffsets) {
          startOffsets[i]=input.readVInt();
          endOffsets[i]=input.readVInt();
        }
        if (hasPayloads) {
          int payloadLength=input.readVInt();
          if (payloads[i] == null) {
            payloads[i]=new BytesRefBuilder();
          }
          payloads[i].grow(payloadLength);
          input.readBytes(payloads[i].bytes(),0,payloadLength);
          payloads[i].setLength(payloadLength);
        }
      }
    }
    private void growBuffers(){
      if (hasPositions) {
        positions=grow(positions,freq);
      }
      if (hasOffsets) {
        startOffsets=grow(startOffsets,freq);
        endOffsets=grow(endOffsets,freq);
      }
      if (hasPayloads) {
        if (payloads.length < freq) {
          payloads=Arrays.copyOf(payloads,ArrayUtil.oversize(freq,RamUsageEstimator.NUM_BYTES_OBJECT_REF));
        }
      }
    }
    @Override public SeekStatus seekCeil(    BytesRef text) throws IOException {
      throw new UnsupportedOperationException();
    }
    @Override public void seekExact(    long ord) throws IOException {
      throw new UnsupportedOperationException("Seek is not supported");
    }
    @Override public BytesRef term() throws IOException {
      return spare.get();
    }
    @Override public long ord() throws IOException {
      throw new UnsupportedOperationException("ordinals are not supported");
    }
    @Override public int docFreq() throws IOException {
      return docFreq;
    }
    @Override public long totalTermFreq() throws IOException {
      return totalTermFrequency;
    }
    @Override public PostingsEnum postings(    Bits liveDocs,    PostingsEnum reuse,    int flags) throws IOException {
      final TermVectorPostingsEnum retVal=(reuse instanceof TermVectorPostingsEnum ? (TermVectorPostingsEnum)reuse : new TermVectorPostingsEnum());
      return retVal.reset(hasPositions ? positions : null,hasOffsets ? startOffsets : null,hasOffsets ? endOffsets : null,hasPayloads ? payloads : null,freq);
    }
  }
;
}
