{
  CloseableHttpClient client=HttpClientBuilder.create().build();
  Sniffer sniffer=new Sniffer(client,RequestConfig.DEFAULT,sniffRequestTimeout,scheme);
  HttpHost httpHost=new HttpHost(server.getHostName(),server.getPort());
  try {
    List<HttpHost> sniffedHosts=sniffer.sniffNodes(httpHost);
    if (sniffResponse.isFailure) {
      fail("sniffNodes should have failed");
    }
    assertThat(sniffedHosts.size(),equalTo(sniffResponse.hosts.size()));
    Iterator<HttpHost> responseHostsIterator=sniffResponse.hosts.iterator();
    for (    HttpHost sniffedHost : sniffedHosts) {
      assertEquals(sniffedHost,responseHostsIterator.next());
    }
  }
 catch (  ElasticsearchResponseException e) {
    if (sniffResponse.isFailure) {
      assertThat(e.getMessage(),containsString("GET http://localhost:" + server.getPort() + "/_nodes/http?timeout="+ sniffRequestTimeout));
      assertThat(e.getMessage(),containsString(Integer.toString(sniffResponse.nodesInfoResponseCode)));
      assertThat(e.getHost(),equalTo(httpHost));
      assertThat(e.getStatusLine().getStatusCode(),equalTo(sniffResponse.nodesInfoResponseCode));
      assertThat(e.getRequestLine().toString(),equalTo("GET /_nodes/http?timeout=" + sniffRequestTimeout + "ms HTTP/1.1"));
    }
 else {
      fail("sniffNodes should have succeeded: " + e.getStatusLine());
    }
  }
}
