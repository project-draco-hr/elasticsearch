{
  boolean changed=false;
  if (nodes.dataNodes().isEmpty()) {
    return changed;
  }
  if (!routingNodes.hasUnassigned()) {
    return changed;
  }
  Iterator<MutableShardRouting> unassignedIterator=routingNodes.unassigned().iterator();
  while (unassignedIterator.hasNext()) {
    MutableShardRouting shard=unassignedIterator.next();
    InternalIndexService indexService=(InternalIndexService)indicesService.indexService(shard.index());
    if (indexService == null) {
      continue;
    }
    if (!indexService.store().persistent()) {
      continue;
    }
    boolean canBeAllocatedToAtLeastOneNode=false;
    for (    DiscoveryNode discoNode : nodes.dataNodes().values()) {
      RoutingNode node=routingNodes.node(discoNode.id());
      if (node == null) {
        continue;
      }
      if (nodeAllocations.canAllocate(shard,node,routingNodes).allocate()) {
        canBeAllocatedToAtLeastOneNode=true;
        break;
      }
    }
    if (!canBeAllocatedToAtLeastOneNode) {
      continue;
    }
    ConcurrentMap<DiscoveryNode,IndexStore.StoreFilesMetaData> shardStores=buildShardStores(nodes,shard);
    long lastSizeMatched=0;
    DiscoveryNode lastDiscoNodeMatched=null;
    RoutingNode lastNodeMatched=null;
    for (    Map.Entry<DiscoveryNode,IndexStore.StoreFilesMetaData> nodeStoreEntry : shardStores.entrySet()) {
      DiscoveryNode discoNode=nodeStoreEntry.getKey();
      IndexStore.StoreFilesMetaData storeFilesMetaData=nodeStoreEntry.getValue();
      logger.trace("{}: checking node [{}]",shard,discoNode);
      if (storeFilesMetaData == null) {
        continue;
      }
      RoutingNode node=routingNodes.node(discoNode.id());
      if (node == null) {
        continue;
      }
      if (nodeAllocations.canAllocate(shard,node,routingNodes) == Decision.NO) {
        continue;
      }
      if (storeFilesMetaData.allocated()) {
        continue;
      }
      if (shard.primary()) {
        BlobStoreIndexGateway indexGateway=(BlobStoreIndexGateway)indexService.gateway();
        try {
          CommitPoint commitPoint=cachedCommitPoints.get(shard.shardId());
          if (commitPoint == null) {
            commitPoint=indexGateway.findCommitPoint(shard.id());
            if (commitPoint != null) {
              cachedCommitPoints.put(shard.shardId(),commitPoint);
            }
 else {
              cachedCommitPoints.put(shard.shardId(),CommitPoint.NULL);
            }
          }
 else           if (commitPoint == CommitPoint.NULL) {
            commitPoint=null;
          }
          if (commitPoint == null) {
            break;
          }
          if (logger.isTraceEnabled()) {
            StringBuilder sb=new StringBuilder(shard + ": checking for pre_allocation (gateway) on node " + discoNode+ "\n");
            sb.append("    gateway_files:\n");
            for (            CommitPoint.FileInfo fileInfo : commitPoint.indexFiles()) {
              sb.append("        [").append(fileInfo.name()).append("]/[").append(fileInfo.physicalName()).append("], size [").append(new ByteSizeValue(fileInfo.length())).append("]\n");
            }
            sb.append("    node_files:\n");
            for (            StoreFileMetaData md : storeFilesMetaData) {
              sb.append("        [").append(md.name()).append("], size [").append(new ByteSizeValue(md.length())).append("]\n");
            }
            logger.trace(sb.toString());
          }
          long sizeMatched=0;
          for (          StoreFileMetaData storeFileMetaData : storeFilesMetaData) {
            CommitPoint.FileInfo fileInfo=commitPoint.findPhysicalIndexFile(storeFileMetaData.name());
            if (fileInfo != null) {
              if (fileInfo.length() == storeFileMetaData.length()) {
                logger.trace("{}: [{}] reusing file since it exists on remote node and on gateway with size [{}]",shard,storeFileMetaData.name(),new ByteSizeValue(storeFileMetaData.length()));
                sizeMatched+=storeFileMetaData.length();
              }
 else {
                logger.trace("{}: [{}] ignore file since it exists on remote node and on gateway but has different size, remote node [{}], gateway [{}]",shard,storeFileMetaData.name(),storeFileMetaData.length(),fileInfo.length());
              }
            }
 else {
              logger.trace("{}: [{}] exists on remote node, does not exists on gateway",shard,storeFileMetaData.name());
            }
          }
          if (sizeMatched > lastSizeMatched) {
            lastSizeMatched=sizeMatched;
            lastDiscoNodeMatched=discoNode;
            lastNodeMatched=node;
            logger.trace("{}: node elected for pre_allocation [{}], total_size_matched [{}]",shard,discoNode,new ByteSizeValue(sizeMatched));
          }
 else {
            logger.trace("{}: node ignored for pre_allocation [{}], total_size_matched [{}] smaller than last_size_matched [{}]",shard,discoNode,new ByteSizeValue(sizeMatched),new ByteSizeValue(lastSizeMatched));
          }
        }
 catch (        Exception e) {
          logger.debug("Failed to guess allocation of primary based on gateway for " + shard,e);
        }
      }
 else {
        MutableShardRouting primaryShard=routingNodes.findPrimaryForReplica(shard);
        if (primaryShard != null && primaryShard.active()) {
          DiscoveryNode primaryNode=nodes.get(primaryShard.currentNodeId());
          if (primaryNode != null) {
            IndexStore.StoreFilesMetaData primaryNodeStore=shardStores.get(primaryNode);
            if (primaryNodeStore != null && primaryNodeStore.allocated()) {
              long sizeMatched=0;
              for (              StoreFileMetaData storeFileMetaData : storeFilesMetaData) {
                if (primaryNodeStore.fileExists(storeFileMetaData.name()) && primaryNodeStore.file(storeFileMetaData.name()).length() == storeFileMetaData.length()) {
                  sizeMatched+=storeFileMetaData.length();
                }
              }
              if (sizeMatched > lastSizeMatched) {
                lastSizeMatched=sizeMatched;
                lastDiscoNodeMatched=discoNode;
                lastNodeMatched=node;
              }
            }
          }
        }
      }
    }
    if (lastNodeMatched != null) {
      if (nodeAllocations.canAllocate(shard,lastNodeMatched,routingNodes) == NodeAllocation.Decision.THROTTLE) {
        if (logger.isTraceEnabled()) {
          logger.debug("[{}][{}]: throttling allocation [{}] to [{}] in order to reuse its unallocated persistent store with total_size [{}]",shard.index(),shard.id(),shard,lastDiscoNodeMatched,new ByteSizeValue(lastSizeMatched));
        }
        unassignedIterator.remove();
        routingNodes.ignoredUnassigned().add(shard);
      }
 else {
        if (logger.isDebugEnabled()) {
          logger.debug("[{}][{}]: allocating [{}] to [{}] in order to reuse its unallocated persistent store with total_size [{}]",shard.index(),shard.id(),shard,lastDiscoNodeMatched,new ByteSizeValue(lastSizeMatched));
        }
        changed=true;
        lastNodeMatched.add(shard);
        unassignedIterator.remove();
      }
    }
  }
  return changed;
}
