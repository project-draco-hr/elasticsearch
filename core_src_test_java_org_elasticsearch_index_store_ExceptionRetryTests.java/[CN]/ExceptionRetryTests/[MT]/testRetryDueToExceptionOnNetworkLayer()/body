{
  final AtomicBoolean exceptionThrown=new AtomicBoolean(false);
  int numDocs=scaledRandomIntBetween(100,1000);
  NodesStatsResponse nodeStats=client().admin().cluster().prepareNodesStats().get();
  NodeStats unluckyNode=randomFrom(nodeStats.getNodes());
  assertAcked(client().admin().indices().prepareCreate("index"));
  ensureGreen("index");
  for (  NodeStats dataNode : nodeStats.getNodes()) {
    MockTransportService mockTransportService=((MockTransportService)internalCluster().getInstance(TransportService.class,dataNode.getNode().name()));
    mockTransportService.addDelegate(internalCluster().getInstance(Discovery.class,unluckyNode.getNode().name()).localNode(),new MockTransportService.DelegateTransport(mockTransportService.original()){
      @Override public void sendRequest(      DiscoveryNode node,      long requestId,      String action,      TransportRequest request,      TransportRequestOptions options) throws IOException, TransportException {
        super.sendRequest(node,requestId,action,request,options);
        if (action.equals(TransportShardBulkAction.ACTION_NAME) && !exceptionThrown.get()) {
          logger.debug("Throw ConnectTransportException");
          exceptionThrown.set(true);
          throw new ConnectTransportException(node,action);
        }
      }
    }
);
  }
  BulkRequestBuilder bulkBuilder=client().prepareBulk();
  for (int i=0; i < numDocs; i++) {
    XContentBuilder doc=null;
    doc=jsonBuilder().startObject().field("foo","bar").endObject();
    bulkBuilder.add(client().prepareIndex("index","type").setSource(doc));
  }
  BulkResponse response=bulkBuilder.get();
  if (response.hasFailures()) {
    for (    BulkItemResponse singleIndexRespons : response.getItems()) {
      if (singleIndexRespons.isFailed()) {
        fail("None of the bulk items should fail but got " + singleIndexRespons.getFailureMessage());
      }
    }
  }
  refresh();
  SearchResponse searchResponse=client().prepareSearch("index").setSize(numDocs * 2).addField("_id").get();
  Set<String> uniqueIds=new HashSet();
  long dupCounter=0;
  boolean found_duplicate_already=false;
  for (int i=0; i < searchResponse.getHits().getHits().length; i++) {
    if (!uniqueIds.add(searchResponse.getHits().getHits()[i].getId())) {
      if (!found_duplicate_already) {
        SearchResponse dupIdResponse=client().prepareSearch("index").setQuery(termQuery("_id",searchResponse.getHits().getHits()[i].getId())).setExplain(true).get();
        assertThat(dupIdResponse.getHits().totalHits(),greaterThan(1l));
        logger.info("found a duplicate id:");
        for (        SearchHit hit : dupIdResponse.getHits()) {
          logger.info("Doc {} was found on shard {}",hit.getId(),hit.getShard().getShardId());
        }
        logger.info("will not print anymore in case more duplicates are found.");
        found_duplicate_already=true;
      }
      dupCounter++;
    }
  }
  assertSearchResponse(searchResponse);
  assertThat(dupCounter,equalTo(0l));
  assertHitCount(searchResponse,numDocs);
}
