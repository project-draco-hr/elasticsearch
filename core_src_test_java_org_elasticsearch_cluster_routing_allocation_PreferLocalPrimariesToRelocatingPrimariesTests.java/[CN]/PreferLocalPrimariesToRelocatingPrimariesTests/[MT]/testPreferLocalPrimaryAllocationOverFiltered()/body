{
  int concurrentRecoveries=randomIntBetween(1,10);
  int primaryRecoveries=randomIntBetween(1,10);
  int numberOfShards=randomIntBetween(5,20);
  int totalNumberOfShards=numberOfShards * 2;
  logger.info("create an allocation with [{}] initial primary recoveries and [{}] concurrent recoveries",primaryRecoveries,concurrentRecoveries);
  AllocationService strategy=createAllocationService(Settings.builder().put("cluster.routing.allocation.node_concurrent_recoveries",concurrentRecoveries).put("cluster.routing.allocation.node_initial_primaries_recoveries",primaryRecoveries).build());
  logger.info("create 2 indices with [{}] no replicas, and wait till all are allocated",numberOfShards);
  MetaData metaData=MetaData.builder().put(IndexMetaData.builder("test1").settings(settings(Version.CURRENT)).numberOfShards(numberOfShards).numberOfReplicas(0)).put(IndexMetaData.builder("test2").settings(settings(Version.CURRENT)).numberOfShards(numberOfShards).numberOfReplicas(0)).build();
  RoutingTable initialRoutingTable=RoutingTable.builder().addAsNew(metaData.index("test1")).addAsNew(metaData.index("test2")).build();
  ClusterState clusterState=ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();
  logger.info("adding two nodes and performing rerouting till all are allocated");
  clusterState=ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode("node1",singletonMap("tag1","value1"))).add(newNode("node2",singletonMap("tag1","value2")))).build();
  RoutingAllocation.Result routingResult=strategy.reroute(clusterState,"reroute");
  clusterState=ClusterState.builder(clusterState).routingResult(routingResult).build();
  while (!clusterState.getRoutingNodes().shardsWithState(INITIALIZING).isEmpty()) {
    routingResult=strategy.applyStartedShards(clusterState,clusterState.getRoutingNodes().shardsWithState(INITIALIZING));
    clusterState=ClusterState.builder(clusterState).routingResult(routingResult).build();
  }
  logger.info("remove one of the nodes and apply filter to move everything from another node");
  metaData=MetaData.builder().put(IndexMetaData.builder(clusterState.metaData().index("test1")).settings(settings(Version.CURRENT).put("index.number_of_shards",numberOfShards).put("index.number_of_replicas",0).put("index.routing.allocation.exclude.tag1","value2").build())).put(IndexMetaData.builder(clusterState.metaData().index("test2")).settings(settings(Version.CURRENT).put("index.number_of_shards",numberOfShards).put("index.number_of_replicas",0).put("index.routing.allocation.exclude.tag1","value2").build())).build();
  clusterState=ClusterState.builder(clusterState).metaData(metaData).nodes(DiscoveryNodes.builder(clusterState.nodes()).remove("node1")).build();
  routingResult=strategy.deassociateDeadNodes(clusterState,true,"reroute");
  clusterState=ClusterState.builder(clusterState).routingResult(routingResult).build();
  logger.info("[{}] primaries should be still started but [{}] other primaries should be unassigned",numberOfShards,numberOfShards);
  assertThat(clusterState.getRoutingNodes().shardsWithState(STARTED).size(),equalTo(numberOfShards));
  assertThat(clusterState.getRoutingNodes().shardsWithState(INITIALIZING).size(),equalTo(0));
  assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(),equalTo(numberOfShards));
  logger.info("start node back up");
  clusterState=ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode("node1",singletonMap("tag1","value1")))).build();
  routingResult=strategy.reroute(clusterState,"reroute");
  clusterState=ClusterState.builder(clusterState).routingResult(routingResult).build();
  while (clusterState.getRoutingNodes().shardsWithState(STARTED).size() < totalNumberOfShards) {
    int localInitializations=0;
    int relocatingInitializations=0;
    for (    ShardRouting routing : clusterState.getRoutingNodes().shardsWithState(INITIALIZING)) {
      if (routing.relocatingNodeId() == null) {
        localInitializations++;
      }
 else {
        relocatingInitializations++;
      }
    }
    int needToInitialize=totalNumberOfShards - clusterState.getRoutingNodes().shardsWithState(STARTED).size() - clusterState.getRoutingNodes().shardsWithState(RELOCATING).size();
    logger.info("local initializations: [{}], relocating: [{}], need to initialize: {}",localInitializations,relocatingInitializations,needToInitialize);
    assertThat(localInitializations,equalTo(Math.min(primaryRecoveries,needToInitialize)));
    clusterState=startRandomInitializingShard(clusterState,strategy);
  }
}
