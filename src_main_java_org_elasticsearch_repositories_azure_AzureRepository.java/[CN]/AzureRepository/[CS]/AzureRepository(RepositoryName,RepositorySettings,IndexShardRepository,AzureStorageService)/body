{
  super(name.getName(),repositorySettings,indexShardRepository);
  String container=repositorySettings.settings().get(AzureStorageService.Fields.CONTAINER,componentSettings.get(AzureStorageService.Fields.CONTAINER,CONTAINER_DEFAULT));
  int concurrentStreams=repositorySettings.settings().getAsInt(AzureStorageService.Fields.CONCURRENT_STREAMS,componentSettings.getAsInt(AzureStorageService.Fields.CONCURRENT_STREAMS,5));
  ExecutorService concurrentStreamPool=EsExecutors.newScaling(1,concurrentStreams,5,TimeUnit.SECONDS,EsExecutors.daemonThreadFactory(settings,"[azure_stream]"));
  this.blobStore=new AzureBlobStore(settings,azureStorageService,container,concurrentStreamPool);
  this.chunkSize=repositorySettings.settings().getAsBytesSize(AzureStorageService.Fields.CHUNK_SIZE,componentSettings.getAsBytesSize(AzureStorageService.Fields.CHUNK_SIZE,new ByteSizeValue(64,ByteSizeUnit.MB)));
  if (this.chunkSize.getMb() > 64) {
    logger.warn("azure repository does not support yet size > 64mb. Fall back to 64mb.");
    this.chunkSize=new ByteSizeValue(64,ByteSizeUnit.MB);
  }
  this.compress=repositorySettings.settings().getAsBoolean(AzureStorageService.Fields.COMPRESS,componentSettings.getAsBoolean(AzureStorageService.Fields.COMPRESS,false));
  String basePath=repositorySettings.settings().get(AzureStorageService.Fields.BASE_PATH,null);
  if (Strings.hasLength(basePath)) {
    basePath=Strings.trimLeadingCharacter(basePath,'/');
    BlobPath path=new BlobPath();
    for (    String elem : Strings.splitStringToArray(basePath,'/')) {
      path=path.add(elem);
    }
    this.basePath=path;
  }
 else {
    this.basePath=BlobPath.cleanPath();
  }
  logger.debug("using container [{}], chunk_size [{}], concurrent_streams [{}], compress [{}], base_path [{}]",container,chunkSize,concurrentStreams,compress,basePath);
}
