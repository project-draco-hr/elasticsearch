{
  double realWordErrorLikelihood=suggestion.realworldErrorLikelyhood();
  final PhraseSuggestion response=new PhraseSuggestion(name,suggestion.getSize());
  final IndexReader indexReader=searcher.getIndexReader();
  List<PhraseSuggestionContext.DirectCandidateGenerator> generators=suggestion.generators();
  final int numGenerators=generators.size();
  final List<CandidateGenerator> gens=new ArrayList<>(generators.size());
  for (int i=0; i < numGenerators; i++) {
    PhraseSuggestionContext.DirectCandidateGenerator generator=generators.get(i);
    DirectSpellChecker directSpellChecker=SuggestUtils.getDirectSpellChecker(generator);
    Terms terms=MultiFields.getTerms(indexReader,generator.field());
    if (terms != null) {
      gens.add(new DirectCandidateGenerator(directSpellChecker,generator.field(),generator.suggestMode(),indexReader,realWordErrorLikelihood,generator.size(),generator.preFilter(),generator.postFilter(),terms));
    }
  }
  final String suggestField=suggestion.getField();
  final Terms suggestTerms=MultiFields.getTerms(indexReader,suggestField);
  if (gens.size() > 0 && suggestTerms != null) {
    final NoisyChannelSpellChecker checker=new NoisyChannelSpellChecker(realWordErrorLikelihood,suggestion.getRequireUnigram(),suggestion.getTokenLimit());
    final BytesRef separator=suggestion.separator();
    WordScorer wordScorer=suggestion.model().newScorer(indexReader,suggestTerms,suggestField,realWordErrorLikelihood,separator);
    Result checkerResult;
    try (TokenStream stream=checker.tokenStream(suggestion.getAnalyzer(),suggestion.getText(),spare,suggestion.getField())){
      checkerResult=checker.getCorrections(stream,new MultiCandidateGeneratorWrapper(suggestion.getShardSize(),gens.toArray(new CandidateGenerator[gens.size()])),suggestion.maxErrors(),suggestion.getShardSize(),wordScorer,suggestion.confidence(),suggestion.gramSize());
    }
     PhraseSuggestion.Entry resultEntry=buildResultEntry(suggestion,spare,checkerResult.cutoffScore);
    response.addTerm(resultEntry);
    final BytesRefBuilder byteSpare=new BytesRefBuilder();
    final CompiledScript collateScript=suggestion.getCollateQueryScript();
    final boolean collatePrune=(collateScript != null) && suggestion.collatePrune();
    for (int i=0; i < checkerResult.corrections.length; i++) {
      Correction correction=checkerResult.corrections[i];
      spare.copyUTF8Bytes(correction.join(SEPARATOR,byteSpare,null,null));
      boolean collateMatch=true;
      if (collateScript != null) {
        final Map<String,Object> vars=suggestion.getCollateScriptParams();
        vars.put(SUGGESTION_TEMPLATE_VAR_NAME,spare.toString());
        final ExecutableScript executable=scriptService.executable(collateScript,vars);
        final BytesReference querySource=(BytesReference)executable.run();
        IndexService indexService=indicesService.indexService(suggestion.getIndex());
        IndexShard shard=indexService.getShard(suggestion.getShard());
        final ParsedQuery parsedQuery=shard.getQueryShardContext().parse(querySource);
        collateMatch=Lucene.exists(searcher,parsedQuery.query());
      }
      if (!collateMatch && !collatePrune) {
        continue;
      }
      Text phrase=new Text(spare.toString());
      Text highlighted=null;
      if (suggestion.getPreTag() != null) {
        spare.copyUTF8Bytes(correction.join(SEPARATOR,byteSpare,suggestion.getPreTag(),suggestion.getPostTag()));
        highlighted=new Text(spare.toString());
      }
      if (collatePrune) {
        resultEntry.addOption(new Suggestion.Entry.Option(phrase,highlighted,(float)(correction.score),collateMatch));
      }
 else {
        resultEntry.addOption(new Suggestion.Entry.Option(phrase,highlighted,(float)(correction.score)));
      }
    }
  }
 else {
    response.addTerm(buildResultEntry(suggestion,spare,Double.MIN_VALUE));
  }
  return response;
}
