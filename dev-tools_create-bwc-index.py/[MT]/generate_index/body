def generate_index(client, version):
    client.indices.delete(index='test', ignore=404)
    num_shards = random.randint(1, 10)
    num_replicas = random.randint(0, 1)
    logging.info('Create single shard test index')
    mappings = {}
    if (not version.startswith('2.')):
        mappings['analyzer_type1'] = {'analyzer': 'standard', 'properties': {'string_with_index_analyzer': {'type': 'string', 'index_analyzer': 'standard', }, 'completion_with_index_analyzer': {'type': 'completion', 'index_analyzer': 'standard', }, }, }
        mappings['analyzer_type2'] = {'index_analyzer': 'standard', 'search_analyzer': 'keyword', 'search_quote_analyzer': 'english', }
    client.indices.create(index='test', body={'settings': {'number_of_shards': 1, 'number_of_replicas': 0, }, 'mappings': mappings, })
    health = client.cluster.health(wait_for_status='green', wait_for_relocating_shards=0)
    assert (health['timed_out'] == False), ('cluster health timed out %s' % health)
    num_docs = random.randint(10, 100)
    index_documents(client, 'test', 'doc', num_docs)
    logging.info('Running basic asserts on the data added')
    run_basic_asserts(client, 'test', 'doc', num_docs)
