{
  ensureOpen();
  if (flush.type() == Flush.Type.NEW_WRITER || flush.type() == Flush.Type.COMMIT_TRANSLOG) {
    if (onGoingRecoveries.get() > 0) {
      throw new FlushNotAllowedEngineException(shardId,"recovery is in progress, flush [" + flush.type() + "] is not allowed");
    }
  }
  int currentFlushing=flushing.incrementAndGet();
  if (currentFlushing > 1 && !flush.waitIfOngoing()) {
    flushing.decrementAndGet();
    throw new FlushNotAllowedEngineException(shardId,"already flushing...");
  }
  flushLock.lock();
  try {
    if (flush.type() == Flush.Type.NEW_WRITER) {
      try (InternalLock _=writeLock.acquire()){
        if (onGoingRecoveries.get() > 0) {
          throw new FlushNotAllowedEngineException(shardId,"Recovery is in progress, flush is not allowed");
        }
        dirty=false;
        try {
{
            final long translogId=translog.currentId();
            indexWriter.setCommitData(MapBuilder.<String,String>newMapBuilder().put(Translog.TRANSLOG_ID_KEY,Long.toString(translogId)).map());
            indexWriter.commit();
            indexWriter.rollback();
          }
          indexWriter=createWriter();
          mergeScheduler.removeListener(this.throttle);
          this.throttle=new IndexThrottle(mergeScheduler,this.logger,indexingService);
          mergeScheduler.addListener(throttle);
          if (flushNeeded || flush.force()) {
            flushNeeded=false;
            long translogId=translogIdGenerator.incrementAndGet();
            indexWriter.setCommitData(MapBuilder.<String,String>newMapBuilder().put(Translog.TRANSLOG_ID_KEY,Long.toString(translogId)).map());
            indexWriter.commit();
            translog.newTranslog(translogId);
          }
          SearcherManager current=this.searcherManager;
          this.searcherManager=buildSearchManager(indexWriter);
          versionMap.setManager(searcherManager);
          try {
            IOUtils.close(current);
          }
 catch (          Throwable t) {
            logger.warn("Failed to close current SearcherManager",t);
          }
          maybePruneDeletedTombstones();
        }
 catch (        Throwable t) {
          throw new FlushFailedEngineException(shardId,t);
        }
      }
     }
 else     if (flush.type() == Flush.Type.COMMIT_TRANSLOG) {
      try (InternalLock _=readLock.acquire()){
        final IndexWriter indexWriter=currentIndexWriter();
        if (onGoingRecoveries.get() > 0) {
          throw new FlushNotAllowedEngineException(shardId,"Recovery is in progress, flush is not allowed");
        }
        if (flushNeeded || flush.force()) {
          flushNeeded=false;
          try {
            long translogId=translogIdGenerator.incrementAndGet();
            translog.newTransientTranslog(translogId);
            indexWriter.setCommitData(MapBuilder.<String,String>newMapBuilder().put(Translog.TRANSLOG_ID_KEY,Long.toString(translogId)).map());
            indexWriter.commit();
            refresh(new Refresh("version_table_flush").force(true));
            translog.makeTransientCurrent();
          }
 catch (          Throwable e) {
            translog.revertTransient();
            throw new FlushFailedEngineException(shardId,e);
          }
        }
      }
       if (enableGcDeletes) {
        pruneDeletedTombstones();
      }
    }
 else     if (flush.type() == Flush.Type.COMMIT) {
      try (InternalLock _=readLock.acquire()){
        final IndexWriter indexWriter=currentIndexWriter();
        try {
          long translogId=translog.currentId();
          indexWriter.setCommitData(MapBuilder.<String,String>newMapBuilder().put(Translog.TRANSLOG_ID_KEY,Long.toString(translogId)).map());
          indexWriter.commit();
        }
 catch (        Throwable e) {
          throw new FlushFailedEngineException(shardId,e);
        }
      }
       if (enableGcDeletes) {
        pruneDeletedTombstones();
      }
    }
 else {
      throw new ElasticsearchIllegalStateException("flush type [" + flush.type() + "] not supported");
    }
    try (InternalLock _=readLock.acquire()){
      ensureOpen();
      readLastCommittedSegmentsInfo();
    }
 catch (    Throwable e) {
      if (!closed) {
        logger.warn("failed to read latest segment infos on flush",e);
        if (Lucene.isCorruptionException(e)) {
          throw new FlushFailedEngineException(shardId,e);
        }
      }
    }
  }
 catch (  FlushFailedEngineException ex) {
    maybeFailEngine(ex,"flush");
    throw ex;
  }
 finally {
    flushLock.unlock();
    flushing.decrementAndGet();
  }
}
