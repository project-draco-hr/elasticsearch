{
  long globalSubsetSize=0;
  long globalSupersetSize=0;
  for (  InternalAggregation aggregation : aggregations) {
    @SuppressWarnings("unchecked") InternalSignificantTerms<A,B> terms=(InternalSignificantTerms<A,B>)aggregation;
    globalSubsetSize+=terms.getSubsetSize();
    globalSupersetSize+=terms.getSupersetSize();
  }
  Map<String,List<B>> buckets=new HashMap<>();
  for (  InternalAggregation aggregation : aggregations) {
    @SuppressWarnings("unchecked") InternalSignificantTerms<A,B> terms=(InternalSignificantTerms<A,B>)aggregation;
    for (    B bucket : terms.getBucketsInternal()) {
      List<B> existingBuckets=buckets.get(bucket.getKeyAsString());
      if (existingBuckets == null) {
        existingBuckets=new ArrayList<>(aggregations.size());
        buckets.put(bucket.getKeyAsString(),existingBuckets);
      }
      existingBuckets.add(bucket.newBucket(bucket.getSubsetDf(),globalSubsetSize,bucket.getSupersetDf(),globalSupersetSize,bucket.aggregations));
    }
  }
  getSignificanceHeuristic().initialize(reduceContext);
  final int size=Math.min(requiredSize,buckets.size());
  BucketSignificancePriorityQueue<B> ordered=new BucketSignificancePriorityQueue<>(size);
  for (  Map.Entry<String,List<B>> entry : buckets.entrySet()) {
    List<B> sameTermBuckets=entry.getValue();
    final B b=sameTermBuckets.get(0).reduce(sameTermBuckets,reduceContext);
    b.updateScore(getSignificanceHeuristic());
    if ((b.score > 0) && (b.subsetDf >= minDocCount)) {
      ordered.insertWithOverflow(b);
    }
  }
  B[] list=createBucketsArray(ordered.size());
  for (int i=ordered.size() - 1; i >= 0; i--) {
    list[i]=ordered.pop();
  }
  return create(globalSubsetSize,globalSupersetSize,Arrays.asList(list));
}
