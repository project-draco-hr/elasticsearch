{
  logger.info("--> starting 3 nodes");
  final String[] nodes=new String[3];
  nodes[0]=cluster().startNode(settingsBuilder().put("gateway.type","local").put("index.number_of_shards",2).put("index.number_of_replicas",2).build());
  nodes[1]=cluster().startNode(settingsBuilder().put("gateway.type","local").put("index.number_of_shards",2).put("index.number_of_replicas",2).build());
  nodes[2]=cluster().startNode(settingsBuilder().put("gateway.type","local").put("index.number_of_shards",2).put("index.number_of_replicas",2).build());
  logger.info("--> indexing...");
  client().prepareIndex("test","type1","1").setSource(jsonBuilder().startObject().field("field","value1").endObject()).get();
  client().admin().indices().prepareFlush().get();
  client().prepareIndex("test","type1","2").setSource(jsonBuilder().startObject().field("field","value2").endObject()).get();
  assertNoFailures(client().admin().indices().prepareRefresh().execute().get());
  logger.info("--> running cluster_health (wait for the shards to startup)");
  ClusterHealthResponse clusterHealth=client().admin().cluster().health(clusterHealthRequest().waitForGreenStatus().waitForActiveShards(6)).actionGet();
  logger.info("--> done cluster_health, status " + clusterHealth.getStatus());
  assertThat(clusterHealth.isTimedOut(),equalTo(false));
  assertThat(clusterHealth.getStatus(),equalTo(ClusterHealthStatus.GREEN));
  for (int i=0; i < 10; i++) {
    assertHitCount(client().prepareCount().setQuery(matchAllQuery()).get(),2l);
  }
  final String nodeToRemove=nodes[between(0,2)];
  logger.info("--> restarting 2 nodes -- kill 1");
  cluster().fullRestart(new RestartCallback(){
    @Override public Settings onNodeStopped(    String nodeName) throws Exception {
      return settingsBuilder().put("gateway.type","local").build();
    }
    @Override public boolean doRestart(    String nodeName){
      return !nodeToRemove.equals(nodeName);
    }
  }
);
  assertThat(awaitBusy(new Predicate<Object>(){
    @Override public boolean apply(    Object input){
      ClusterStateResponse clusterStateResponse=cluster().smartClient().admin().cluster().prepareState().setMasterNodeTimeout("500ms").get();
      return !clusterStateResponse.getState().routingTable().index("test").allPrimaryShardsActive();
    }
  }
,30,TimeUnit.SECONDS),equalTo(true));
  logger.info("--> change the recovery.initial_shards setting, and make sure its recovered");
  client().admin().indices().prepareUpdateSettings("test").setSettings(settingsBuilder().put("recovery.initial_shards",1)).get();
  logger.info("--> running cluster_health (wait for the shards to startup), 4 shards since we only have 2 nodes");
  clusterHealth=client().admin().cluster().health(clusterHealthRequest().waitForYellowStatus().waitForActiveShards(4)).actionGet();
  logger.info("--> done cluster_health, status " + clusterHealth.getStatus());
  assertThat(clusterHealth.isTimedOut(),equalTo(false));
  assertThat(clusterHealth.getStatus(),equalTo(ClusterHealthStatus.YELLOW));
  for (int i=0; i < 10; i++) {
    assertHitCount(client().prepareCount().setQuery(matchAllQuery()).get(),2l);
  }
}
