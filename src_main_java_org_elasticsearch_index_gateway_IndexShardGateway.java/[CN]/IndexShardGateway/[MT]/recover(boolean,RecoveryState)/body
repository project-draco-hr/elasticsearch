{
  indexShard.prepareForIndexRecovery();
  long version=-1;
  long translogId=-1;
  final Set<String> typesToUpdate=Sets.newHashSet();
  SegmentInfos si=null;
  indexShard.store().incRef();
  try {
    try {
      indexShard.store().failIfCorrupted();
      try {
        si=Lucene.readSegmentInfos(indexShard.store().directory());
      }
 catch (      Throwable e) {
        String files="_unknown_";
        try {
          files=Arrays.toString(indexShard.store().directory().listAll());
        }
 catch (        Throwable e1) {
          files+=" (failure=" + ExceptionsHelper.detailedMessage(e1) + ")";
        }
        if (indexShouldExists) {
          throw new IndexShardGatewayRecoveryException(shardId(),"shard allocated for local recovery (post api), should exist, but doesn't, current files: " + files,e);
        }
      }
      if (si != null) {
        if (indexShouldExists) {
          version=si.getVersion();
          if (si.getUserData().containsKey(Translog.TRANSLOG_ID_KEY)) {
            translogId=Long.parseLong(si.getUserData().get(Translog.TRANSLOG_ID_KEY));
          }
 else {
            translogId=version;
          }
          logger.trace("using existing shard data, translog id [{}]",translogId);
        }
 else {
          logger.trace("cleaning existing shard, shouldn't exists");
          IndexWriter writer=new IndexWriter(indexShard.store().directory(),new IndexWriterConfig(Lucene.STANDARD_ANALYZER).setOpenMode(IndexWriterConfig.OpenMode.CREATE));
          writer.close();
        }
      }
    }
 catch (    Throwable e) {
      throw new IndexShardGatewayRecoveryException(shardId(),"failed to fetch index version after copying it over",e);
    }
    recoveryState.getIndex().updateVersion(version);
    try {
      final RecoveryState.Index index=recoveryState.getIndex();
      if (si != null) {
        final Directory directory=indexShard.store().directory();
        for (        String name : Lucene.files(si)) {
          long length=directory.fileLength(name);
          index.addFileDetail(name,length,true);
        }
      }
    }
 catch (    IOException e) {
      logger.debug("failed to list file details",e);
    }
    Path recoveringTranslogFile=null;
    if (translogId == -1) {
      logger.trace("no translog id set (indexShouldExist [{}])",indexShouldExists);
    }
 else {
      final Translog translog=indexShard.translog();
      final Path translogName=translog.getPath(translogId);
      logger.trace("try recover from translog file {} locations: {}",translogName,Arrays.toString(translog.locations()));
      OUTER:       for (      Path translogLocation : translog.locations()) {
        for (        Path recoveryFiles : FileSystemUtils.files(translogLocation,translogName.getFileName() + "{.recovering,}")) {
          logger.trace("Translog file found in {}",recoveryFiles);
          recoveringTranslogFile=recoveryFiles;
          break OUTER;
        }
        logger.trace("Translog file NOT found in {} - continue",translogLocation);
      }
    }
    indexShard.prepareForTranslogRecovery();
    if (recoveringTranslogFile == null || Files.exists(recoveringTranslogFile) == false) {
      indexShard.finalizeRecovery();
      indexShard.postRecovery("post recovery from gateway, no translog");
      return;
    }
    StreamInput in=null;
    try {
      if (logger.isTraceEnabled()) {
        logger.trace("recovering translog file: {} length: {}",recoveringTranslogFile,Files.size(recoveringTranslogFile));
      }
      TranslogStream stream=TranslogStreams.translogStreamFor(recoveringTranslogFile);
      try {
        in=stream.openInput(recoveringTranslogFile);
      }
 catch (      TruncatedTranslogException e) {
        logger.trace("ignoring truncation exception, the translog is either empty or half-written",e);
      }
      while (true) {
        if (in == null) {
          break;
        }
        Translog.Operation operation;
        try {
          if (stream instanceof LegacyTranslogStream) {
            in.readInt();
          }
          operation=stream.read(in);
        }
 catch (        EOFException e) {
          logger.trace("ignoring translog EOF exception, the last operation was not properly written",e);
          break;
        }
catch (        IOException e) {
          logger.trace("ignoring translog IO exception, the last operation was not properly written",e);
          break;
        }
        try {
          Engine.IndexingOperation potentialIndexOperation=indexShard.performRecoveryOperation(operation);
          if (potentialIndexOperation != null && potentialIndexOperation.parsedDoc().mappingsModified()) {
            if (!typesToUpdate.contains(potentialIndexOperation.docMapper().type())) {
              typesToUpdate.add(potentialIndexOperation.docMapper().type());
            }
          }
          recoveryState.getTranslog().addTranslogOperations(1);
        }
 catch (        ElasticsearchException e) {
          if (e.status() == RestStatus.BAD_REQUEST) {
            logger.info("ignoring recovery of a corrupt translog entry",e);
          }
 else {
            throw e;
          }
        }
      }
    }
 catch (    Throwable e) {
      IOUtils.closeWhileHandlingException(indexShard.translog());
      throw new IndexShardGatewayRecoveryException(shardId,"failed to recover shard",e);
    }
 finally {
      IOUtils.closeWhileHandlingException(in);
    }
    try {
      FlushRequest flushRequest=new FlushRequest();
      flushRequest.force(false);
      flushRequest.waitIfOngoing(false);
      indexShard.flush(flushRequest);
    }
 catch (    FlushNotAllowedEngineException e) {
      logger.debug("skipping flush at end of recovery (not allowed)",e);
    }
    indexShard.finalizeRecovery();
    indexShard.postRecovery("post recovery from gateway");
    try {
      Files.deleteIfExists(recoveringTranslogFile);
    }
 catch (    Exception ex) {
      logger.debug("Failed to delete recovering translog file {}",ex,recoveringTranslogFile);
    }
  }
 catch (  IOException e) {
    throw new IndexShardGatewayRecoveryException(shardId,"failed to recovery from gateway",e);
  }
 finally {
    indexShard.store().decRef();
  }
  for (  final String type : typesToUpdate) {
    final CountDownLatch latch=new CountDownLatch(1);
    mappingUpdatedAction.updateMappingOnMaster(indexService.index().name(),indexService.mapperService().documentMapper(type),indexService.indexUUID(),new MappingUpdatedAction.MappingUpdateListener(){
      @Override public void onMappingUpdate(){
        latch.countDown();
      }
      @Override public void onFailure(      Throwable t){
        latch.countDown();
        logger.debug("failed to send mapping update post recovery to master for [{}]",t,type);
      }
    }
);
    cancellableThreads.execute(new CancellableThreads.Interruptable(){
      @Override public void run() throws InterruptedException {
        try {
          if (latch.await(waitForMappingUpdatePostRecovery.millis(),TimeUnit.MILLISECONDS) == false) {
            logger.debug("waited for mapping update on master for [{}], yet timed out",type);
          }
        }
 catch (        InterruptedException e) {
          logger.debug("interrupted while waiting for mapping update");
          throw e;
        }
      }
    }
);
  }
}
