{
  if (random == null) {
    random=RandomizedTest.getRandom();
  }
  failures=new CopyOnWriteArrayList<>();
  writers=new Thread[writerCount];
  stopLatch=new CountDownLatch(writers.length);
  logger.info("--> creating {} indexing threads (auto start: [{}], numOfDocs: [{}])",writerCount,autoStart,numOfDocs);
  for (int i=0; i < writers.length; i++) {
    final int indexerId=i;
    final boolean batch=random.nextBoolean();
    final Random threadRandom=new Random(random.nextLong());
    writers[i]=new Thread(){
      @Override public void run(){
        long id=-1;
        try {
          startLatch.await();
          logger.info("**** starting indexing thread {}",indexerId);
          while (!stop.get()) {
            if (batch) {
              int batchSize=threadRandom.nextInt(20) + 1;
              if (hasBudget.get()) {
                batchSize=Math.max(Math.min(batchSize,availableBudget.availablePermits()),1);
                if (!availableBudget.tryAcquire(batchSize,250,TimeUnit.MILLISECONDS)) {
                  continue;
                }
              }
              BulkRequestBuilder bulkRequest=client.prepareBulk();
              for (int i=0; i < batchSize; i++) {
                id=idGenerator.incrementAndGet();
                bulkRequest.add(client.prepareIndex(index,type,Long.toString(id)).setSource(generateSource(id,threadRandom)));
              }
              BulkResponse bulkResponse=bulkRequest.get();
              for (              BulkItemResponse bulkItemResponse : bulkResponse) {
                if (!bulkItemResponse.isFailed()) {
                  indexCounter.incrementAndGet();
                }
 else {
                  throw new ElasticsearchException("bulk request failure, id: [" + bulkItemResponse.getFailure().getId() + "] message: "+ bulkItemResponse.getFailure().getMessage());
                }
              }
            }
 else {
              if (hasBudget.get() && !availableBudget.tryAcquire(250,TimeUnit.MILLISECONDS)) {
                continue;
              }
              id=idGenerator.incrementAndGet();
              client.prepareIndex(index,type,Long.toString(id)).setSource(generateSource(id,threadRandom)).get();
              indexCounter.incrementAndGet();
            }
          }
          logger.info("**** done indexing thread {}  stop: {} numDocsIndexed: {}",indexerId,stop.get(),indexCounter.get());
        }
 catch (        Throwable e) {
          failures.add(e);
          logger.warn("**** failed indexing thread {} on doc id {}",e,indexerId,id);
        }
 finally {
          stopLatch.countDown();
        }
      }
    }
;
    writers[i].start();
  }
  if (autoStart) {
    start(numOfDocs);
  }
}
