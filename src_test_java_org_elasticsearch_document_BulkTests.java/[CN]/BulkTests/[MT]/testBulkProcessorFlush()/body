{
  final AtomicReference<BulkResponse> responseRef=new AtomicReference<>();
  final AtomicReference<Throwable> failureRef=new AtomicReference<>();
  final CountDownLatch latch=new CountDownLatch(1);
  BulkProcessor.Listener listener=new BulkProcessor.Listener(){
    @Override public void beforeBulk(    long executionId,    BulkRequest request){
    }
    @Override public void afterBulk(    long executionId,    BulkRequest request,    BulkResponse response){
      responseRef.set(response);
      latch.countDown();
    }
    @Override public void afterBulk(    long executionId,    BulkRequest request,    Throwable failure){
      failureRef.set(failure);
      latch.countDown();
    }
  }
;
  try (BulkProcessor processor=BulkProcessor.builder(client(),listener).setBulkActions(6).setConcurrentRequests(1).setName("foo").build()){
    Map<String,Object> data=Maps.newHashMap();
    data.put("foo","bar");
    processor.add(new IndexRequest("test","test","1").source(data));
    processor.add(new IndexRequest("test","test","2").source(data));
    processor.add(new IndexRequest("test","test","3").source(data));
    processor.add(new IndexRequest("test","test","4").source(data));
    processor.add(new IndexRequest("test","test","5").source(data));
    processor.flush();
    latch.await();
    BulkResponse response=responseRef.get();
    Throwable error=failureRef.get();
    assertThat(error,nullValue());
    assertThat("Could not get a bulk response even after an explicit flush.",response,notNullValue());
    assertThat(response.getItems().length,is(5));
  }
 }
