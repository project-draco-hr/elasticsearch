{
  Map<Version,BytesReference> serializedStates=Maps.newHashMap();
  Map<Version,BytesReference> serializedDiffs=Maps.newHashMap();
  final ClusterState clusterState=clusterChangedEvent.state();
  final ClusterState previousState=clusterChangedEvent.previousState();
  final AtomicBoolean timedOutWaitingForNodes=new AtomicBoolean(false);
  final TimeValue publishTimeout=discoverySettings.getPublishTimeout();
  final boolean sendFullVersion=!discoverySettings.getPublishDiff() || previousState == null;
  Diff<ClusterState> diff=null;
  for (  final DiscoveryNode node : nodesToPublishTo) {
    if (sendFullVersion || !previousState.nodes().nodeExists(node.id())) {
      sendFullClusterState(clusterState,serializedStates,node,timedOutWaitingForNodes,publishTimeout,publishResponseHandler);
    }
 else {
      if (diff == null) {
        diff=clusterState.diff(previousState);
      }
      sendClusterStateDiff(clusterState,diff,serializedDiffs,node,timedOutWaitingForNodes,publishTimeout,publishResponseHandler);
    }
  }
  if (publishTimeout.millis() > 0) {
    try {
      timedOutWaitingForNodes.set(!publishResponseHandler.awaitAllNodes(publishTimeout));
      if (timedOutWaitingForNodes.get()) {
        DiscoveryNode[] pendingNodes=publishResponseHandler.pendingNodes();
        if (pendingNodes.length > 0) {
          logger.warn("timed out waiting for all nodes to process published state [{}] (timeout [{}], pending nodes: {})",clusterState.version(),publishTimeout,pendingNodes);
        }
      }
    }
 catch (    InterruptedException e) {
      Thread.currentThread().interrupt();
    }
  }
}
