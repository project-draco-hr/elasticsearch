{
  logger.info("--> starting [node1] ...");
  startNode("node1");
  logger.info("--> creating test index ...");
  client("node1").admin().indices().prepareCreate("test").execute().actionGet();
  final AtomicLong idGenerator=new AtomicLong();
  final AtomicLong indexCounter=new AtomicLong();
  final AtomicBoolean stop=new AtomicBoolean(false);
  Thread[] writers=new Thread[5];
  logger.info("--> starting {} indexing threads",writers.length);
  final CountDownLatch stopLatch=new CountDownLatch(writers.length);
  for (int i=0; i < writers.length; i++) {
    final int indexerId=i;
    writers[i]=new Thread(){
      @Override public void run(){
        try {
          logger.info("**** starting indexing thread {}",indexerId);
          while (!stop.get()) {
            long id=idGenerator.incrementAndGet();
            client("node1").prepareIndex("test","type1",Long.toString(id)).setSource(MapBuilder.<String,Object>newMapBuilder().put("test","value" + id).map()).execute().actionGet();
            indexCounter.incrementAndGet();
          }
          logger.info("**** done indexing thread {}",indexerId);
        }
 catch (        Exception e) {
          logger.warn("**** failed indexing thread {}",e,indexerId);
        }
 finally {
          stopLatch.countDown();
        }
      }
    }
;
    writers[i].start();
  }
  logger.info("--> waiting for 2000 docs to be indexed ...");
  while (client("node1").prepareCount().setQuery(matchAllQuery()).execute().actionGet().count() < 2000) {
    Thread.sleep(100);
    client("node1").admin().indices().prepareRefresh().execute().actionGet();
  }
  logger.info("--> 2000 docs indexed");
  logger.info("--> flushing the index ....");
  client("node1").admin().indices().prepareFlush().execute().actionGet();
  logger.info("--> waiting for 4000 docs to be indexed ...");
  while (client("node1").prepareCount().setQuery(matchAllQuery()).execute().actionGet().count() < 4000) {
    Thread.sleep(100);
    client("node1").admin().indices().prepareRefresh().execute().actionGet();
  }
  logger.info("--> 4000 docs indexed");
  logger.info("--> starting [node2] ...");
  startNode("node2");
  logger.info("--> starting [node3] ...");
  startNode("node3");
  logger.info("--> starting [node4] ...");
  startNode("node4");
  logger.info("--> waiting for GREEN health status ...");
  assertThat(client("node1").admin().cluster().prepareHealth().setTimeout("1m").setWaitForGreenStatus().setWaitForNodes("4").execute().actionGet().timedOut(),equalTo(false));
  logger.info("--> waiting for 15000 docs to be indexed ...");
  while (client("node1").prepareCount().setQuery(matchAllQuery()).execute().actionGet().count() < 15000) {
    Thread.sleep(100);
    client("node1").admin().indices().prepareRefresh().execute().actionGet();
  }
  logger.info("--> 15000 docs indexed");
  stop.set(true);
  stopLatch.await();
  logger.info("--> marking and waiting for indexing threads to stop ...");
  stop.set(true);
  stopLatch.await();
  logger.info("--> indexing threads stopped");
  logger.info("--> refreshing the index");
  client("node1").admin().indices().prepareRefresh().execute().actionGet();
  logger.info("--> verifying indexed content");
  for (int i=0; i < 10; i++) {
    assertThat(client("node1").prepareCount().setQuery(matchAllQuery()).execute().actionGet().count(),equalTo(indexCounter.get()));
  }
}
