{
  Codec codec=new TestCodec();
  Directory d=new RAMDirectory();
  IndexWriterConfig config=new IndexWriterConfig(Lucene.VERSION,new WhitespaceAnalyzer(Lucene.VERSION));
  config.setCodec(codec);
  IndexWriter writer=new IndexWriter(d,config);
  for (int i=0; i < 100; i++) {
    writer.addDocument(Arrays.asList(new TextField("foo","foo bar foo bar",Store.YES),new TextField("some_other_field","1234",Store.YES)));
  }
  writer.forceMerge(1);
  writer.commit();
  DirectoryReader reader=DirectoryReader.open(writer,false);
  List<AtomicReaderContext> leaves=reader.leaves();
  assertThat(leaves.size(),equalTo(1));
  AtomicReader ar=leaves.get(0).reader();
  Terms terms=ar.terms("foo");
  Terms some_other_field=ar.terms("some_other_field");
  assertThat(terms.size(),equalTo(2l));
  assertThat(terms,not(instanceOf(BloomFilterPostingsFormat.BloomFilteredTerms.class)));
  assertThat(some_other_field,not(instanceOf(BloomFilterPostingsFormat.BloomFilteredTerms.class)));
  TermsEnum iterator=terms.iterator(null);
  Set<String> expected=new HashSet<String>();
  expected.add("foo");
  expected.add("bar");
  while (iterator.next() != null) {
    expected.remove(iterator.term().utf8ToString());
  }
  assertThat(expected.size(),equalTo(0));
  reader.close();
  writer.close();
  d.close();
}
