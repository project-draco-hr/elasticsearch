{
  Map<Object,List<InternalTerms.Bucket>> buckets=new HashMap<>();
  long sumDocCountError=0;
  long otherDocCount=0;
  InternalTerms<A,B> referenceTerms=null;
  for (  InternalAggregation aggregation : aggregations) {
    InternalTerms<A,B> terms=(InternalTerms<A,B>)aggregation;
    if (referenceTerms == null && !terms.getClass().equals(UnmappedTerms.class)) {
      referenceTerms=(InternalTerms<A,B>)aggregation;
    }
    if (referenceTerms != null && !referenceTerms.getClass().equals(terms.getClass()) && !terms.getClass().equals(UnmappedTerms.class)) {
      throw new AggregationExecutionException("Merging/Reducing the aggregations failed " + "when computing the aggregation [ Name: " + referenceTerms.getName() + ", Type: "+ referenceTerms.type()+ " ]"+ " because: "+ "the field you gave in the aggregation query "+ "existed as two different types "+ "in two different indices");
    }
    otherDocCount+=terms.getSumOfOtherDocCounts();
    final long thisAggDocCountError;
    if (terms.buckets.size() < this.shardSize || this.order == InternalOrder.TERM_ASC || this.order == InternalOrder.TERM_DESC) {
      thisAggDocCountError=0;
    }
 else     if (InternalOrder.isCountDesc(this.order)) {
      thisAggDocCountError=terms.buckets.get(terms.buckets.size() - 1).docCount;
    }
 else {
      thisAggDocCountError=-1;
    }
    if (sumDocCountError != -1) {
      if (thisAggDocCountError == -1) {
        sumDocCountError=-1;
      }
 else {
        sumDocCountError+=thisAggDocCountError;
      }
    }
    terms.docCountError=thisAggDocCountError;
    for (    Bucket bucket : terms.buckets) {
      bucket.docCountError=thisAggDocCountError;
      List<Bucket> bucketList=buckets.get(bucket.getKey());
      if (bucketList == null) {
        bucketList=new ArrayList<>();
        buckets.put(bucket.getKey(),bucketList);
      }
      bucketList.add(bucket);
    }
  }
  final int size=Math.min(requiredSize,buckets.size());
  BucketPriorityQueue ordered=new BucketPriorityQueue(size,order.comparator(null));
  for (  List<Bucket> sameTermBuckets : buckets.values()) {
    final Bucket b=sameTermBuckets.get(0).reduce(sameTermBuckets,reduceContext);
    if (b.docCountError != -1) {
      if (sumDocCountError == -1) {
        b.docCountError=-1;
      }
 else {
        b.docCountError=sumDocCountError - b.docCountError;
      }
    }
    if (b.docCount >= minDocCount) {
      Terms.Bucket removed=ordered.insertWithOverflow(b);
      if (removed != null) {
        otherDocCount+=removed.getDocCount();
      }
    }
  }
  Bucket[] list=new Bucket[ordered.size()];
  for (int i=ordered.size() - 1; i >= 0; i--) {
    list[i]=(Bucket)ordered.pop();
  }
  long docCountError;
  if (sumDocCountError == -1) {
    docCountError=-1;
  }
 else {
    docCountError=aggregations.size() == 1 ? 0 : sumDocCountError;
  }
  return create(name,Arrays.asList(list),docCountError,otherDocCount,this);
}
