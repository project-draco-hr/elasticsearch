def generate_index(client, version, index_name):
    client.indices.delete(index=index_name, ignore=404)
    logging.info('Create single shard test index')
    mappings = {}
    warmers = {}
    if (parse_version(version) < parse_version('2.0.0-alpha1')):
        warmers['warmer1'] = {'source': {'query': {'match_all': {}, }, }, }
        mappings['analyzer_type1'] = {'analyzer': 'standard', 'properties': {'string_with_index_analyzer': {'type': 'string', 'index_analyzer': 'standard', }, }, }
        if ((not version.startswith('0.20')) and (version not in ['0.90.0.Beta1', '0.90.0.RC1', '0.90.0.RC2', '0.90.0', '0.90.1', '0.90.2'])):
            mappings['analyzer_type1']['properties']['completion_with_index_analyzer'] = {'type': 'completion', 'index_analyzer': 'standard', }
        mappings['analyzer_type2'] = {'index_analyzer': 'standard', 'search_analyzer': 'keyword', 'search_quote_analyzer': 'english', }
        mappings['index_name_and_path'] = {'properties': {'parent_multi_field': {'type': 'string', 'path': 'just_name', 'fields': {'raw': {'type': 'string', 'index': 'not_analyzed', 'index_name': 'raw_multi_field', }, }, }, 'field_with_index_name': {'type': 'string', 'index_name': 'custom_index_name_for_field', }, }, }
        mappings['meta_fields'] = {'_routing': {'required': 'false', }, }
        mappings['custom_formats'] = {'properties': {'string_with_custom_postings': {'type': 'string', 'postings_format': 'Lucene41', }, 'long_with_custom_doc_values': {'type': 'long', 'doc_values_format': 'Lucene42', }, }, }
        mappings['auto_boost'] = {'_all': {'auto_boost': True, }, }
    mappings['doc'] = {'properties': {}, }
    supports_dots_in_field_names = (parse_version(version) >= parse_version('2.4.0'))
    if supports_dots_in_field_names:
        mappings['doc']['properties'].update({'field.with.dots': {'type': 'string', 'boost': 4, }, })
    if (parse_version(version) < parse_version('5.0.0-alpha1')):
        mappings['norms'] = {'properties': {'string_with_norms_disabled': {'type': 'string', 'norms': {'enabled': False, }, }, 'string_with_norms_enabled': {'type': 'string', 'index': 'not_analyzed', 'norms': {'enabled': True, 'loading': 'eager', }, }, }, }
        mappings['doc'] = {'properties': {'string': {'type': 'string', 'boost': 4, }, }, }
    else:
        mappings['norms'] = {'properties': {'string_with_norms_disabled': {'type': 'text', 'norms': False, }, 'string_with_norms_enabled': {'type': 'keyword', 'index': 'not_analyzed', 'norms': True, 'eager_global_ordinals': True, }, }, }
        mappings['doc']['properties'].update({'string': {'type': 'text', 'boost': 4, }, })
    settings = {'number_of_shards': 1, 'number_of_replicas': 0, }
    if (version.startswith('0.') or version.startswith('1.')):
        settings['gc_deletes'] = ('60000',)
        settings['merge.policy.max_merged_segment'] = '5368709120'
    body = {'settings': settings, 'mappings': mappings, }
    if warmers:
        body['warmers'] = warmers
    client.indices.create(index=index_name, body=body)
    health = client.cluster.health(wait_for_status='green', wait_for_relocating_shards=0)
    assert (health['timed_out'] == False), ('cluster health timed out %s' % health)
    num_docs = random.randint(2000, 3000)
    if (version == '1.1.0'):
        num_docs = int((num_docs / 10))
    index_documents(client, index_name, 'doc', num_docs, supports_dots_in_field_names)
    logging.info('Running basic asserts on the data added')
    run_basic_asserts(client, index_name, 'doc', num_docs)
    return (num_docs, supports_dots_in_field_names)
