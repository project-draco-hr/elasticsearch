{
  List<InternalAggregation> aggregations=reduceContext.aggregations();
  if (aggregations.size() == 1) {
    InternalTerms terms=(InternalTerms)aggregations.get(0);
    terms.trimExcessEntries(reduceContext.cacheRecycler());
    return terms;
  }
  InternalTerms reduced=null;
  Recycler.V<DoubleObjectOpenHashMap<List<Bucket>>> buckets=null;
  for (  InternalAggregation aggregation : aggregations) {
    InternalTerms terms=(InternalTerms)aggregation;
    if (terms instanceof UnmappedTerms) {
      continue;
    }
    if (reduced == null) {
      reduced=terms;
    }
    if (buckets == null) {
      buckets=reduceContext.cacheRecycler().doubleObjectMap(terms.buckets.size());
    }
    for (    Terms.Bucket bucket : terms.buckets) {
      List<Bucket> existingBuckets=buckets.v().get(((Bucket)bucket).term);
      if (existingBuckets == null) {
        existingBuckets=new ArrayList<Bucket>(aggregations.size());
        buckets.v().put(((Bucket)bucket).term,existingBuckets);
      }
      existingBuckets.add((Bucket)bucket);
    }
  }
  if (reduced == null) {
    return (UnmappedTerms)aggregations.get(0);
  }
  final int size=Math.min(requiredSize,buckets.v().size());
  BucketPriorityQueue ordered=new BucketPriorityQueue(size,order.comparator(null));
  boolean[] states=buckets.v().allocated;
  Object[] internalBuckets=buckets.v().values;
  for (int i=0; i < states.length; i++) {
    if (states[i]) {
      List<DoubleTerms.Bucket> sameTermBuckets=(List<DoubleTerms.Bucket>)internalBuckets[i];
      final InternalTerms.Bucket b=sameTermBuckets.get(0).reduce(sameTermBuckets,reduceContext.cacheRecycler());
      if (b.getDocCount() >= minDocCount) {
        ordered.insertWithOverflow(b);
      }
    }
  }
  buckets.release();
  InternalTerms.Bucket[] list=new InternalTerms.Bucket[ordered.size()];
  for (int i=ordered.size() - 1; i >= 0; i--) {
    list[i]=(Bucket)ordered.pop();
  }
  reduced.buckets=Arrays.asList(list);
  return reduced;
}
