{
  if (logger.isTraceEnabled()) {
    logger.trace("Performing ClusterInfoUpdateJob");
  }
  if (isMaster && this.reschedule) {
    if (logger.isTraceEnabled()) {
      logger.trace("Scheduling next run for updating cluster info in: {}",updateFrequency.toString());
    }
    try {
      threadPool.schedule(updateFrequency,executorName(),new SubmitReschedulingClusterInfoUpdatedJob());
    }
 catch (    EsRejectedExecutionException ex) {
      logger.debug("Reschedule cluster info service was rejected",ex);
    }
  }
  if (!enabled) {
    if (logger.isTraceEnabled()) {
      logger.trace("Skipping ClusterInfoUpdatedJob since it is disabled");
    }
    return;
  }
  CountDownLatch nodeLatch=updateNodeStats(new ActionListener<NodesStatsResponse>(){
    @Override public void onResponse(    NodesStatsResponse nodeStatses){
      Map<String,DiskUsage> newUsages=new HashMap<>();
      for (      NodeStats nodeStats : nodeStatses.getNodes()) {
        if (nodeStats.getFs() == null) {
          logger.warn("Unable to retrieve node FS stats for {}",nodeStats.getNode().name());
        }
 else {
          long available=0;
          long total=0;
          for (          FsInfo.Path info : nodeStats.getFs()) {
            available+=info.getAvailable().bytes();
            total+=info.getTotal().bytes();
          }
          String nodeId=nodeStats.getNode().id();
          String nodeName=nodeStats.getNode().getName();
          if (logger.isTraceEnabled()) {
            logger.trace("node: [{}], total disk: {}, available disk: {}",nodeId,total,available);
          }
          newUsages.put(nodeId,new DiskUsage(nodeId,nodeName,total,available));
        }
      }
      usages=ImmutableMap.copyOf(newUsages);
    }
    @Override public void onFailure(    Throwable e){
      if (e instanceof ReceiveTimeoutTransportException) {
        logger.error("NodeStatsAction timed out for ClusterInfoUpdateJob (reason [{}])",e.getMessage());
      }
 else {
        if (e instanceof ClusterBlockException) {
          if (logger.isTraceEnabled()) {
            logger.trace("Failed to execute NodeStatsAction for ClusterInfoUpdateJob",e);
          }
        }
 else {
          logger.warn("Failed to execute NodeStatsAction for ClusterInfoUpdateJob",e);
        }
        usages=ImmutableMap.of();
      }
    }
  }
);
  CountDownLatch indicesLatch=updateIndicesStats(new ActionListener<IndicesStatsResponse>(){
    @Override public void onResponse(    IndicesStatsResponse indicesStatsResponse){
      ShardStats[] stats=indicesStatsResponse.getShards();
      HashMap<String,Long> newShardSizes=new HashMap<>();
      for (      ShardStats s : stats) {
        long size=s.getStats().getStore().sizeInBytes();
        String sid=ClusterInfo.shardIdentifierFromRouting(s.getShardRouting());
        if (logger.isTraceEnabled()) {
          logger.trace("shard: {} size: {}",sid,size);
        }
        newShardSizes.put(sid,size);
      }
      shardSizes=ImmutableMap.copyOf(newShardSizes);
    }
    @Override public void onFailure(    Throwable e){
      if (e instanceof ReceiveTimeoutTransportException) {
        logger.error("IndicesStatsAction timed out for ClusterInfoUpdateJob (reason [{}])",e.getMessage());
      }
 else {
        if (e instanceof ClusterBlockException) {
          if (logger.isTraceEnabled()) {
            logger.trace("Failed to execute IndicesStatsAction for ClusterInfoUpdateJob",e);
          }
        }
 else {
          logger.warn("Failed to execute IndicesStatsAction for ClusterInfoUpdateJob",e);
        }
        shardSizes=ImmutableMap.of();
      }
    }
  }
);
  try {
    nodeLatch.await(fetchTimeout.getMillis(),TimeUnit.MILLISECONDS);
  }
 catch (  InterruptedException e) {
    Thread.currentThread().interrupt();
    logger.warn("Failed to update node information for ClusterInfoUpdateJob within 15s timeout");
  }
  try {
    indicesLatch.await(fetchTimeout.getMillis(),TimeUnit.MILLISECONDS);
  }
 catch (  InterruptedException e) {
    Thread.currentThread().interrupt();
    logger.warn("Failed to update shard information for ClusterInfoUpdateJob within 15s timeout");
  }
  for (  Listener l : listeners) {
    try {
      l.onNewInfo(getClusterInfo());
    }
 catch (    Exception e) {
      logger.info("Failed executing ClusterInfoService listener",e);
    }
  }
}
