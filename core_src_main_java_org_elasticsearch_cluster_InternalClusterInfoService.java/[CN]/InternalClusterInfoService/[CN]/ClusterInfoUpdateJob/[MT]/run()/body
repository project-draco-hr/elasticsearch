{
  if (logger.isTraceEnabled()) {
    logger.trace("Performing ClusterInfoUpdateJob");
  }
  if (isMaster && this.reschedule) {
    if (logger.isTraceEnabled()) {
      logger.trace("Scheduling next run for updating cluster info in: {}",updateFrequency.toString());
    }
    try {
      threadPool.schedule(updateFrequency,executorName(),new SubmitReschedulingClusterInfoUpdatedJob());
    }
 catch (    EsRejectedExecutionException ex) {
      logger.debug("Reschedule cluster info service was rejected",ex);
    }
  }
  if (!enabled) {
    if (logger.isTraceEnabled()) {
      logger.trace("Skipping ClusterInfoUpdatedJob since it is disabled");
    }
    return;
  }
  CountDownLatch nodeLatch=updateNodeStats(new ActionListener<NodesStatsResponse>(){
    @Override public void onResponse(    NodesStatsResponse nodeStatses){
      Map<String,DiskUsage> newLeastAvaiableUsages=new HashMap<>();
      Map<String,DiskUsage> newMostAvaiableUsages=new HashMap<>();
      fillDiskUsagePerNode(logger,nodeStatses.getNodes(),newLeastAvaiableUsages,newMostAvaiableUsages);
      leastAvailableSpaceUsages=Collections.unmodifiableMap(newLeastAvaiableUsages);
      mostAvailableSpaceUsages=Collections.unmodifiableMap(newMostAvaiableUsages);
    }
    @Override public void onFailure(    Throwable e){
      if (e instanceof ReceiveTimeoutTransportException) {
        logger.error("NodeStatsAction timed out for ClusterInfoUpdateJob (reason [{}])",e.getMessage());
      }
 else {
        if (e instanceof ClusterBlockException) {
          if (logger.isTraceEnabled()) {
            logger.trace("Failed to execute NodeStatsAction for ClusterInfoUpdateJob",e);
          }
        }
 else {
          logger.warn("Failed to execute NodeStatsAction for ClusterInfoUpdateJob",e);
        }
        leastAvailableSpaceUsages=Collections.emptyMap();
        mostAvailableSpaceUsages=Collections.emptyMap();
      }
    }
  }
);
  CountDownLatch indicesLatch=updateIndicesStats(new ActionListener<IndicesStatsResponse>(){
    @Override public void onResponse(    IndicesStatsResponse indicesStatsResponse){
      ShardStats[] stats=indicesStatsResponse.getShards();
      HashMap<String,Long> newShardSizes=new HashMap<>();
      for (      ShardStats s : stats) {
        long size=s.getStats().getStore().sizeInBytes();
        String sid=ClusterInfo.shardIdentifierFromRouting(s.getShardRouting());
        if (logger.isTraceEnabled()) {
          logger.trace("shard: {} size: {}",sid,size);
        }
        newShardSizes.put(sid,size);
      }
      shardSizes=Collections.unmodifiableMap(newShardSizes);
    }
    @Override public void onFailure(    Throwable e){
      if (e instanceof ReceiveTimeoutTransportException) {
        logger.error("IndicesStatsAction timed out for ClusterInfoUpdateJob (reason [{}])",e.getMessage());
      }
 else {
        if (e instanceof ClusterBlockException) {
          if (logger.isTraceEnabled()) {
            logger.trace("Failed to execute IndicesStatsAction for ClusterInfoUpdateJob",e);
          }
        }
 else {
          logger.warn("Failed to execute IndicesStatsAction for ClusterInfoUpdateJob",e);
        }
        shardSizes=Collections.emptyMap();
      }
    }
  }
);
  try {
    nodeLatch.await(fetchTimeout.getMillis(),TimeUnit.MILLISECONDS);
  }
 catch (  InterruptedException e) {
    Thread.currentThread().interrupt();
    logger.warn("Failed to update node information for ClusterInfoUpdateJob within 15s timeout");
  }
  try {
    indicesLatch.await(fetchTimeout.getMillis(),TimeUnit.MILLISECONDS);
  }
 catch (  InterruptedException e) {
    Thread.currentThread().interrupt();
    logger.warn("Failed to update shard information for ClusterInfoUpdateJob within 15s timeout");
  }
  for (  Listener l : listeners) {
    try {
      l.onNewInfo(getClusterInfo());
    }
 catch (    Exception e) {
      logger.info("Failed executing ClusterInfoService listener",e);
    }
  }
}
