{
  AtomicReader reader=context.reader();
  Terms terms=reader.terms(getFieldNames().indexName());
  AtomicOrdinalsFieldData data=null;
  NonEstimatingEstimator estimator=new NonEstimatingEstimator(breakerService.getBreaker());
  if (terms == null) {
    data=AbstractAtomicOrdinalsFieldData.empty();
    estimator.afterLoad(null,data.ramBytesUsed());
    return data;
  }
  PositiveIntOutputs outputs=PositiveIntOutputs.getSingleton();
  org.apache.lucene.util.fst.Builder<Long> fstBuilder=new org.apache.lucene.util.fst.Builder<>(INPUT_TYPE.BYTE1,outputs);
  final IntsRef scratch=new IntsRef();
  final long numTerms;
  if (regex == null && frequency == null) {
    numTerms=terms.size();
  }
 else {
    numTerms=-1;
  }
  final float acceptableTransientOverheadRatio=fieldDataType.getSettings().getAsFloat("acceptable_transient_overhead_ratio",OrdinalsBuilder.DEFAULT_ACCEPTABLE_OVERHEAD_RATIO);
  boolean success=false;
  try (OrdinalsBuilder builder=new OrdinalsBuilder(numTerms,reader.maxDoc(),acceptableTransientOverheadRatio)){
    TermsEnum termsEnum=filter(terms,reader);
    DocsEnum docsEnum=null;
    for (BytesRef term=termsEnum.next(); term != null; term=termsEnum.next()) {
      final long termOrd=builder.nextOrdinal();
      fstBuilder.add(Util.toIntsRef(term,scratch),(long)termOrd);
      docsEnum=termsEnum.docs(null,docsEnum,DocsEnum.FLAG_NONE);
      for (int docId=docsEnum.nextDoc(); docId != DocsEnum.NO_MORE_DOCS; docId=docsEnum.nextDoc()) {
        builder.addDoc(docId);
      }
    }
    FST<Long> fst=fstBuilder.finish();
    final Ordinals ordinals=builder.build(fieldDataType.getSettings());
    data=new FSTBytesAtomicFieldData(fst,ordinals);
    success=true;
    return data;
  }
  finally {
    if (success) {
      estimator.afterLoad(null,data.ramBytesUsed());
    }
  }
}
